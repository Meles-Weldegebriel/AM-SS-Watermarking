{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6bb419c",
   "metadata": {},
   "source": [
    "## Pseudonym error performance under multiple interference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "id": "fb307f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "import statistics as stats\n",
    "import scipy.io\n",
    "from scipy.spatial.distance import hamming\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1228,
   "id": "2ab62694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_string(timestamp):\n",
    "    '''\n",
    "    Helper function to get data and time from timestamp\n",
    "    INPUT: timestamp\n",
    "    OUTPUT: data and time. Example: 01-04-2023, 19:50:27\n",
    "    '''\n",
    "    date_time = datetime.datetime.fromtimestamp(int(timestamp))\n",
    "    return date_time.strftime(\"%m-%d-%Y, %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1229,
   "id": "992d842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def JsonLoad(folder, json_file):\n",
    "    '''\n",
    "    Load parameters from the saved json file\n",
    "    INPUT\n",
    "    ----\n",
    "        folder: path to the measurement folder. Example: \"SHOUT/Results/Shout_meas_01-04-2023_18-50-26\"\n",
    "        json_file: the json file with all the specifications. Example: '/save_iq_w_tx_gold.json'\n",
    "    OUTPUT\n",
    "    ----\n",
    "        samps_per_chip: samples per chip\n",
    "        wotxrepeat: number of repeating IQ sample collection w/o transmission. Used as an input to \n",
    "        traverse_dataset() func\n",
    "        rxrate: sampling rate at the receiver side\n",
    "    '''\n",
    "    #config_file = folder+'/'+json_file\n",
    "    #config_file = \"\"+\"/\"+str(folder)+\"/save_iq_w_tx_file.json\"\n",
    "    config_dict = json.load(open(json_file))[0]\n",
    "    nsamps = config_dict['nsamps']\n",
    "    rxrate = config_dict['rxrate']\n",
    "    rxfreq = config_dict['rxfreq']\n",
    "    wotxrepeat = config_dict['wotxrepeat']\n",
    "    rxrepeat = config_dict['rxrepeat']\n",
    "    txnodes = config_dict['txclients']\n",
    "    rxnodes = config_dict['rxclients']\n",
    "\n",
    "    return rxrepeat, rxrate, txnodes, rxnodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1230,
   "id": "05dbd0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse_dataset(meas_folder):\n",
    "    '''\n",
    "    Load data from hdf5 format measurement file\n",
    "    INPUT\n",
    "    ----\n",
    "        meas_folder: path to the measurement folder. Example: \"SHOUT/Results/Shout_meas_01-04-2023_18-50-26\"\n",
    "    OUTPUT\n",
    "    ----\n",
    "        data: Collected IQ samples w/ transmission. It is indexed by the transmitter name\n",
    "        noise: Collected IQ samples w/o transmission. It is indexed by the transmitter name\n",
    "        txrxloc: transmitter and receiver names\n",
    "    '''\n",
    "    data = {}\n",
    "    noise = {}\n",
    "    txrxloc = {}\n",
    "\n",
    "    dataset = h5py.File(meas_folder + '/measurements.hdf5', \"r\") #meas_folder\n",
    "    #print(\"Dataset meta data:\", list(dataset.attrs.items()))\n",
    "    for cmd in dataset.keys():\n",
    "        #print(\"Command:\", cmd)\n",
    "        if cmd == 'saveiq':\n",
    "            cmd_time = list(dataset[cmd].keys())[0]\n",
    "           # print(\"  Timestamp:\", get_time_string(cmd_time))\n",
    "            #print(\"  Command meta data:\", list(dataset[cmd][cmd_time].attrs.items()))\n",
    "            for rx_gain in dataset[cmd][cmd_time].keys():\n",
    "               # print(\"   RX gain:\", rx_gain)\n",
    "                for rx in dataset[cmd][cmd_time][rx_gain].keys():\n",
    "                    print(\"\")\n",
    "                    #print(\"     RX:\", rx)\n",
    "                    #print(\"       Measurement items:\", list(dataset[cmd][cmd_time][rx_gain][rx].keys()))\n",
    "        elif cmd == 'saveiq_w_tx':\n",
    "            cmd_time = list(dataset[cmd].keys())[0]\n",
    "            #print(\"  Timestamp:\", get_time_string(cmd_time))\n",
    "            #print(\"  Command meta data:\", list(dataset[cmd][cmd_time].attrs.items()))\n",
    "            for tx in dataset[cmd][cmd_time].keys():\n",
    "                #print(\"   TX:\", tx)\n",
    "                \n",
    "                if tx == 'wo_tx':\n",
    "                    for rx_gain in dataset[cmd][cmd_time][tx].keys():\n",
    "                        #print(\"       RX gain:\", rx_gain)\n",
    "                       # print(dataset[cmd][cmd_time][tx][rx_gain].keys())\n",
    "                        for rx in dataset[cmd][cmd_time][tx][rx_gain].keys():\n",
    "                            #print(\"         RX:\", rx)\n",
    "                            #print(\"           Measurement items:\", list(dataset[cmd][cmd_time][tx][rx_gain][rx].keys()))\n",
    "                            repeat = np.shape(dataset[cmd][cmd_time][tx][rx_gain][rx]['rxsamples'])[0]\n",
    "                            #print(\"         repeat\", repeat)\n",
    "\n",
    "                            samplesNotx =  dataset[cmd][cmd_time][tx][rx_gain][rx]['rxsamples'][:repeat, :]\n",
    "                            namelist = rx.split('-')\n",
    "                            noise[namelist[1]] = samplesNotx\n",
    "                else:\n",
    "                    for tx_gain in dataset[cmd][cmd_time][tx].keys():\n",
    "                        #print(\"     TX gain:\", tx_gain)\n",
    "                        for rx_gain in dataset[cmd][cmd_time][tx][tx_gain].keys():\n",
    "                            #print(\"       RX gain:\", rx_gain)\n",
    "                            #print(dataset[cmd][cmd_time][tx][tx_gain][rx_gain].keys())\n",
    "                            for rx in dataset[cmd][cmd_time][tx][tx_gain][rx_gain].keys():\n",
    "                                repeat = np.shape(dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx]['rxsamples'])[0]\n",
    "                                #print(\"         RX:\", rx, \"; samples shape\", np.shape(dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx]['rxsamples']))\n",
    "                                #print(\"         Measurement items:\", list(dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx].keys()))\n",
    "                                # print(\"         rxloc\", (dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx]['rxloc'][0]))\n",
    "                                # peak avg check\n",
    "                                \n",
    "                                txrxloc.setdefault(tx, []).extend([rx]*repeat)\n",
    "                                rxsamples = dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx]['rxsamples'][:repeat, :]\n",
    "                                data.setdefault(tx, []).append(np.array(rxsamples))\n",
    "\n",
    "        else:                       \n",
    "            print('Unsupported command: ', cmd)\n",
    "\n",
    "    return data, noise, txrxloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "id": "07ebe29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotOnePSDForEachLink(rx_data, txrxloc, samp_rate=2e6, repeats=10):\n",
    "    for txname in rx_data:\n",
    "        print(txname)\n",
    "        for i in range(0, len(rx_data[txname]), repeats):\n",
    "            plt.figure()\n",
    "            plt.psd(rx_data[txname][i][1], Fs = samp_rate/1000)\n",
    "            #plt.ylim(-110, -60)\n",
    "            #plt.yticks(ticks=[-110, -100, -90, -80, -70, -60])\n",
    "            plt.grid('on')\n",
    "            plt.title('TX: {} RX: {}'.format(txname, txrxloc[txname][i]))\n",
    "            plt.xlabel('Frequency (kHz)')\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fd61f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1232,
   "id": "b628d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURPOSE: perform preamble synchronization\n",
    "#          Uses the (complex-valued) preamble signal. The cross-correlation \n",
    "#          of the preamble signal and the received signal (at the time\n",
    "#          when the preamble is received) should have highest magnitude\n",
    "#          at the index delay where the preamble approximately starts.  \n",
    "# INPUT:   rx0: received signal (with a frequency offset)\n",
    "#          preambleSignal: complex, known, transmitted preamble signal \n",
    "# OUTPUT:  lagIndex: the index of rx0 where the preamble signal has highest \n",
    "#              cross-correlation\n",
    "#\n",
    "def crossCorrelationMax(rx0, preambleSignal):\n",
    "\n",
    "    # Cross correlate with the preamble to find it in the noisy signal\n",
    "    lags      = signal.correlation_lags(len(rx0), len(preambleSignal), mode='valid')\n",
    "    xcorr_out = signal.correlate(rx0, preambleSignal, mode='valid')\n",
    "    xcorr_mag = np.abs(xcorr_out)\n",
    "    # Don't let it sync to the end of the packet.\n",
    "    packetLenSamples = 13440800\n",
    "    maxIndex = np.argmax(xcorr_mag[:len(xcorr_mag)-packetLenSamples])\n",
    "    lagIndex = lags[maxIndex]\n",
    "    \n",
    "#     print('The old lag ' + str(lagIndex))\n",
    "    # Try to use the second lagIndex if the first one is not strong enough\n",
    "    packetLenSamples = 0\n",
    "    maxIndex2 = np.argmax(xcorr_mag[:len(xcorr_mag)-packetLenSamples])\n",
    "    lagIndex2 = lags[maxIndex2]\n",
    "    \n",
    "# #     print(\"xcorr_mag[maxIndex2]\", xcorr_mag[maxIndex2])\n",
    "    \n",
    "    if abs(xcorr_mag[maxIndex2]) > abs(xcorr_mag[maxIndex]):\n",
    "        lagIndex = lags[maxIndex2] - Frame_length\n",
    "        print('The new lag ' + str(lagIndex))\n",
    "    else:\n",
    "        print('The old lag ' + str(lagIndex))\n",
    "    #Plot the selected signal.\n",
    "    plt.figure(1)\n",
    "    fig, subfigs = plt.subplots(2,1)\n",
    "    subfigs[0].plot(np.real(rx0), label='Real RX Signal')\n",
    "    subfigs[0].plot(np.imag(rx0), label='Imag RX Signal')\n",
    "    scale_factor = np.mean(np.abs(rx0))/np.mean(np.abs(preambleSignal))\n",
    "    subfigs[0].plot(range(lagIndex, lagIndex + len(preambleSignal)), scale_factor*np.real(preambleSignal), label='Preamble')\n",
    "    #subfigs[0].legend()\n",
    "    subfigs[1].plot(lags, xcorr_mag, label='|X-Correlation|')\n",
    "    plt.xlabel('Sample Index', fontsize=14)\n",
    "    plt.show()\n",
    "    #plt.tight_layout()\n",
    "\n",
    "    return lagIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1233,
   "id": "fdc19c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2bits(message):\n",
    "    # Convert to characters of '1' and '0' in a vector.\n",
    "    temp_message = []\n",
    "    final_message = []\n",
    "    for each in message:\n",
    "        temp_message.append(format(ord(each), '07b'))\n",
    "    for every in temp_message:\n",
    "        for digit in every:\n",
    "            final_message.append(int(digit))\n",
    "    return final_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1234,
   "id": "09e2083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Calculate_mean(x):\n",
    "#     swap = np.zeros(49,)\n",
    "#     for i in range(49):\n",
    "#         swap[i] = sum(abs(x[i*N:(i+1)*N])**2)\n",
    "#         print('Received power:',swap[i])\n",
    "#     return np.median(swap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1235,
   "id": "6f47bb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "def binvector2str(binvector):\n",
    "    #binvector = binvector[0]\n",
    "    length = len(binvector)\n",
    "    eps = np.finfo('float').eps\n",
    "    if abs(length/7 - round(length/7)) > eps:\n",
    "        print('Length of bit stream must be a multiple of 7 to convert to a string.')\n",
    "    # Each character requires 7 bits in standard ASCII\n",
    "    num_characters = round(length/7)\n",
    "    # Maximum value is first in the vector. Otherwise would use 0:1:length-1\n",
    "    start = 6\n",
    "    bin_values = []\n",
    "    while start >= 0:\n",
    "        bin_values.append(int(math.pow(2,start)))\n",
    "        start = start - 1\n",
    "    bin_values = np.array(bin_values)\n",
    "    bin_values = np.transpose(bin_values)\n",
    "    str_out = '' # Initialize character vector\n",
    "    for i in range(num_characters):\n",
    "        single_char = binvector[i*7:i*7+7]\n",
    "        value = 0\n",
    "        for counter in range(len(single_char)):\n",
    "            value = value + (int(single_char[counter]) * int(bin_values[counter]))\n",
    "        str_out += chr(int(value))\n",
    "    return str_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1236,
   "id": "14fe25e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURPOSE: Convert binary data to M-ary by making groups of log2(M)\n",
    "#          bits and converting each bit to one M-ary digit.\n",
    "# INPUT: Binary digit vector, with length as a multiple of log2(M)\n",
    "# OUTPUT: M-ary digit vector\n",
    "def binary2mary(data, M):\n",
    "\n",
    "    log2M   = round(np.log2(M))\n",
    "    # integer number of bits per group\n",
    "    if (len(data) % log2M) != 0:\n",
    "        print('Input to binary2mary must be divisible by log2(m).')\n",
    "    data.shape = (len(data)//log2M, log2M)\n",
    "    binaryValuesArray = 2**np.arange(log2M)\n",
    "    marydata = data.dot(binaryValuesArray)\n",
    "    return marydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "id": "db1237df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURPOSE: convert input data stream to signal space values for\n",
    "#          a particular modulation type (as specified by the inputVec\n",
    "#          and outputVec).\n",
    "# INPUT: data (groups of bits)\n",
    "# OUTPUT: signal space values\n",
    "def lut(data, inputVec, outputVec):\n",
    "    if len(inputVec) != len(outputVec):\n",
    "        print('Input and Output vectors must have identical length')\n",
    "    # Initialize output\n",
    "    output = np.zeros(data.shape)\n",
    "    # For each possible data value\n",
    "    eps = np.finfo('float').eps\n",
    "    for i in range(len(inputVec)):\n",
    "        # Find the indices where data is equal to that input value\n",
    "        for k in range(len(data)):\n",
    "            if abs(data[k]-inputVec[i]) < eps:\n",
    "                # Set those indices in the output to be the appropriate output value.\n",
    "                output[k] = outputVec[i]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a1579",
   "metadata": {},
   "source": [
    "# Pseudonym Decoding Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "id": "8b791e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudonym_mesage = 'STOP'\n",
    "\n",
    "pseudonym_packet = text2bits(pseudonym_mesage)\n",
    "pseudonym_length = len(pseudonym_packet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1240,
   "id": "a40cb119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 1240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Protocol parameters!!!\n",
    "'''\n",
    "FFT = 64 # FFT size for extracting IQ sample in each subcarrier\n",
    "OFDM_size = 80 # OFDM symbol with cyclic prefix\n",
    "data_size = 48 # data_subcarriers\n",
    "# mess_length = 560\n",
    "Frame_length = 13440800\n",
    "packet = 6000 # number of bits per pseudonym bit\n",
    "samples = packet//10 # number of samples per chip\n",
    "CP = 16\n",
    "repeat =10\n",
    "actual_message = 'I have done my PhD in electrical engineering at WashU. What a journey it has been!'\n",
    "len(actual_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1241,
   "id": "990f05eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CP = FFT//4  # 25% cyclic prefix\n",
    "pilotValue = 2.83+2.83j # known values for pilots\n",
    "pseudonymValue = 1.4142+1.4142j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1242,
   "id": "aa450a3d-54f4-4f00-b59f-de6536de92ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCarriers = np.array([-26,-25,-24,-23,-22,-20,-19,-18,-17,-16,-15,-14,-13,-12,-11,-10,-9,-8,-6,\n",
    "                    -5,-4,-3,-2,-1,0,1,2,3,4,5,6,8,9,10,11,12,13,14,15,16,17,18,19,20,22,23,24,25])\n",
    "pseudonymCarrier = np.array([26])\n",
    "pilotCarriers = np.array([-21,-7,7,21])\n",
    "guardCarriers = np.array([-32,-31,-30,-29,-28,-27,27,28,29,30,31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1243,
   "id": "9bc1334b-8d1e-4a6a-a734-a1581141210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate HTSTF signals for time synchronization\n",
    "def Generate_HTSTF():\n",
    "    data = scipy.io.loadmat('HTSTF.mat')\n",
    "    new_data = data['stf'].reshape((1,len(data['stf'])))\n",
    "    preamble = np.tile(new_data,10)[0]\n",
    "    return preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1244,
   "id": "ee247de7-f115-43b4-bd71-ee22f2a5a6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FFT for data of window size=64\n",
    "def DFT_data(x, n =64):\n",
    "    return np.fft.fft(x,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1245,
   "id": "823cda88",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Calculates FFT to recover the frequency domain signal in subcarriers and stores them in a matrix '''\n",
    "\n",
    "def subchannel_data(x):\n",
    "    sort_data = np.zeros((FFT, len(x)//OFDM_size), dtype = np.complex64)\n",
    "    for i in range(len(x)//OFDM_size):\n",
    "        y = x[i*OFDM_size:(i+1)*OFDM_size]\n",
    "        sort_data[:,i] = np.fft.fftshift(DFT_data(y[CP:],n=64))  \n",
    "    return sort_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1246,
   "id": "eff14e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate the power in each pseudonym bit and store it in matrix\n",
    "def Cal_subch_power(x):\n",
    "    sub_power = np.zeros((FFT,1))\n",
    "    for i in range(FFT):\n",
    "        sub_power[i] = sum(abs(x[i,:])**2)\n",
    "    return sub_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1247,
   "id": "9fac4d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "calculates the distance between two arrays.\n",
    "'''\n",
    "def Distance(X,Y):\n",
    "    count = 0\n",
    "    for i in range(len(X)):\n",
    "        if X[i]!= Y[i]:\n",
    "            count +=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1248,
   "id": "a24b40cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make p-bit decisions by comparing patterns on bit-0 and bit-1\n",
    "## Trace changes in power with the p-bit and compare it with the known chip pattern.\n",
    "## This algorithm improves pseudonym detection in the presence of non-Gaussion type interferences\n",
    "\n",
    "def Matched_Filter_Pseudonym_Detection_Algorithm(x):\n",
    "    matching_filter0 =np.array([-1,1,-1,1,-1,1,-1,1,-1,1])\n",
    "    matching_filter1 =np.array([1,-1,1,-1,1,-1,1,-1,1,-1])\n",
    "    p_bit = []\n",
    "    for i in range(28):\n",
    "        pbit_data = x[i*OFDM_size*packet:(i+1)*packet*OFDM_size] # slices samples into one p-bit data = 6000 samples\n",
    "        \n",
    "        power = []\n",
    "        Cr = []       \n",
    "        threshold = 0.0\n",
    "        quantization_level = np.array([1,-1])\n",
    "        for j in range(10):\n",
    "            chip_data = pbit_data[j*OFDM_size*samples:(j+1)*OFDM_size*samples]\n",
    "            FFT_matrix = subchannel_data(chip_data)\n",
    "            subchannel_power = Cal_subch_power(FFT_matrix)\n",
    "            power.append(subchannel_power[48,0])\n",
    "       \n",
    "        # plt.plot(power)\n",
    "        # plt.show()\n",
    "\n",
    "        for k in range(1,10):\n",
    "            if power[k] > power[k-1]:\n",
    "                Cr.append(quantization_level[0])\n",
    "            else:\n",
    "                Cr.append(quantization_level[1])\n",
    "            \n",
    "        if np.dot(Cr,matching_filter1[1:]) >= np.dot(Cr,matching_filter0[1:]): # p-bit decision done by comparing p-bit powers with the threshold.\n",
    "            p_bit.append(1)\n",
    "        else:\n",
    "            p_bit.append(0)   \n",
    "    return np.array(p_bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1249,
   "id": "837635d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_Folders(x):\n",
    "    r = []\n",
    "    for root, dirs, files in os.walk(x):\n",
    "        r.append(dirs)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1250,
   "id": "a24c8013",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Checks if pseudonyms are decoded correctly in each repeat of shout transmission.\n",
    "One experiment has 10 repeats.\n",
    "'''\n",
    "def Average_Pseudonym_Error(x):\n",
    "    # Load parameters from the JSON file which describe what was measured\n",
    " \n",
    "    #folder = x\n",
    "    jsonfile = \"save_iq_w_tx_file.json\"\n",
    "    rxrepeat, samp_rate, txlocs, rxlocs = JsonLoad(x, jsonfile)\n",
    "    # Load data from the HDF5 file, save IQ sample arrays\n",
    "    rx_data, rx_noise, txrxloc = traverse_dataset(x)\n",
    "    samp_rate = 2e6\n",
    "\n",
    "    txloc = 'cbrssdr1-ustar-comp'\n",
    "    rxloc = 'cbrssdr1-browning-comp'\n",
    "    \n",
    "    #Calculate SNR\n",
    "    Noise = rx_noise['browning'][0]\n",
    "    noise_power = sum(abs(Noise)**2)/len(Noise)\n",
    "#     print(\"Noise Power:\",noise_power)\n",
    "    rx_data[txloc] = np.vstack(rx_data[txloc])\n",
    "    rxloc_arr = np.array(txrxloc[txloc])       \n",
    "\n",
    "    # initialize error\n",
    "    pseudonym_BER = 0\n",
    "    P_s = 0\n",
    "    for i in range(repeat):\n",
    "        repNum = i\n",
    "        rx_data[txloc] = np.vstack(rx_data[txloc])\n",
    "        rxloc_arr = np.array(txrxloc[txloc])\n",
    "        rx0 = rx_data[txloc][rxloc_arr==rxloc][repNum]\n",
    "    \n",
    "\n",
    "        # synchronize pseudonym using preamble signal\n",
    "        preambleSignal = Generate_HTSTF()\n",
    "        lagIndex = crossCorrelationMax(rx0,preambleSignal)\n",
    "        \n",
    "        start = lagIndex + len(preambleSignal)\n",
    "        Rx_signal = rx0[start:]\n",
    "               \n",
    "        pseudonym_estimate = Matched_Filter_Pseudonym_Detection_Algorithm(Rx_signal)\n",
    "        print('Detected Pseudonym:',binvector2str(pseudonym_estimate), '\\n')\n",
    "        repeat_BER = Distance(pseudonym_estimate,pseudonym_packet)\n",
    "        if  repeat_BER !=0:\n",
    "            print(\"Errors Found:\",repeat_BER)\n",
    "        print(\"Repeat Number:\", i, \"Number of Errors:\",repeat_BER)\n",
    "        pseudonym_BER += repeat_BER\n",
    " \n",
    "        P_s += sum(abs(Rx_signal)**2)/len(Rx_signal)\n",
    "    \n",
    "    signal_power = P_s/repeat\n",
    "    \n",
    "    return pseudonym_BER, signal_power, noise_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1251,
   "id": "40f28914",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Computes the average pseudonym error in the experiment.\n",
    "Experiment data is stored in folders that contain 10 repeats each.\n",
    "'''\n",
    "def Prob_Pseudonym_Error(x):\n",
    "    folders = Extract_Folders(x)[0]\n",
    "    num_folders = len(folders)\n",
    "    print('Number of folders:',num_folders)\n",
    "    pseudonym_BER = 0\n",
    "    signal,noise = 0,0\n",
    "    noise_power = []\n",
    "    Exp_power = []\n",
    "    for i in range(num_folders):\n",
    "        print(folders[i])\n",
    "        error,s,n= Average_Pseudonym_Error(x + '/'+folders[i])\n",
    "        \n",
    "        pseudonym_BER += error\n",
    "        signal += s\n",
    "        noise += n\n",
    "        noise_power.append(n)\n",
    "\n",
    "    Eb_No = 10*(np.log10(0.5*(signal-noise)/noise))\n",
    "    \n",
    "    print(\"total number of pseudonym bit errors:\", pseudonym_BER)\n",
    "    return pseudonym_BER/(repeat*num_folders*pseudonym_length), Eb_No, noise_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1252,
   "id": "730424fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of folders: 2\n",
      "Shout_meas_08-11-2024_14-33-42\n",
      "The old lag 1843180\n",
      "Detected Pseudonym: STOP \n",
      "\n",
      "Repeat Number: 0 Number of Errors: 0\n",
      "The old lag 13014300\n",
      "Detected Pseudonym: STOP \n",
      "\n",
      "Repeat Number: 1 Number of Errors: 0\n",
      "The old lag 7011323\n",
      "Detected Pseudonym: h)J' \n",
      "\n",
      "Errors Found: 19\n",
      "Repeat Number: 2 Number of Errors: 19\n",
      "The old lag 10475180\n",
      "Detected Pseudonym: STOP \n",
      "\n",
      "Repeat Number: 3 Number of Errors: 0\n",
      "The old lag 10205596\n",
      "Detected Pseudonym: STOP \n",
      "\n",
      "Repeat Number: 4 Number of Errors: 0\n",
      "The new lag 8935948\n",
      "Detected Pseudonym: STOP \n",
      "\n",
      "Repeat Number: 5 Number of Errors: 0\n",
      "The new lag 9666396\n",
      "Detected Pseudonym: STOP \n",
      "\n",
      "Repeat Number: 6 Number of Errors: 0\n",
      "The old lag 8396700\n",
      "Detected Pseudonym: STOP \n",
      "\n",
      "Repeat Number: 7 Number of Errors: 0\n",
      "The new lag 9127212\n",
      "Detected Pseudonym: STOP \n",
      "\n",
      "Repeat Number: 8 Number of Errors: 0\n",
      "The old lag 8857596\n",
      "Detected Pseudonym: STOP \n",
      "\n",
      "Repeat Number: 9 Number of Errors: 0\n",
      "Shout_meas_08-11-2024_13-59-45\n",
      "The new lag 5484929\n",
      "Detected Pseudonym: R>B\u000e \n",
      "\n",
      "Errors Found: 13\n",
      "Repeat Number: 0 Number of Errors: 13\n",
      "The old lag 97108\n",
      "Detected Pseudonym: STOP \n",
      "\n",
      "Repeat Number: 1 Number of Errors: 0\n",
      "The new lag 10268356\n",
      "Detected Pseudonym: STOP \n",
      "\n",
      "Repeat Number: 2 Number of Errors: 0\n",
      "The new lag 8998724\n",
      "Detected Pseudonym: STOP \n",
      "\n",
      "Repeat Number: 3 Number of Errors: 0\n",
      "The old lag 8729156\n",
      "Detected Pseudonym: STOP \n",
      "\n",
      "Repeat Number: 4 Number of Errors: 0\n",
      "The old lag 6459588\n",
      "Detected Pseudonym: STOP \n",
      "\n",
      "Repeat Number: 5 Number of Errors: 0\n",
      "The old lag 4189892\n",
      "Detected Pseudonym: STOP \n",
      "\n",
      "Repeat Number: 6 Number of Errors: 0\n",
      "The old lag 3920356\n",
      "Detected Pseudonym: STOP \n",
      "\n",
      "Repeat Number: 7 Number of Errors: 0\n",
      "The old lag 3611837\n",
      "Detected Pseudonym: \f",
      "+0/ \n",
      "\n",
      "Errors Found: 27\n",
      "Repeat Number: 8 Number of Errors: 27\n",
      "The new lag 1381172\n",
      "Detected Pseudonym: STOP \n",
      "\n",
      "Repeat Number: 9 Number of Errors: 0\n",
      "total number of pseudonym bit errors: 59\n"
     ]
    }
   ],
   "source": [
    "#x,y,AWGN = Prob_Pseudonym_Error(\"10dB_gain\")\n",
    "x,y,AWGN_RFI = Prob_Pseudonym_Error(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1253,
   "id": "b97bc262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR: -17.650730068980454 \n",
      " Pseudonym_BER: 0.10535714285714286\n"
     ]
    }
   ],
   "source": [
    "print('SNR:',y,'\\n Pseudonym_BER:',x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
