{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6bb419c",
   "metadata": {},
   "source": [
    "# Pseudonym Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "id": "fb307f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import datetime\n",
    "import scipy.signal as signal\n",
    "\n",
    "import statistics as stats\n",
    "import os\n",
    "import scipy.io\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "id": "ad67a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Protocol parameters!!!\n",
    "'''\n",
    "packet = 6000\n",
    "samples = 600\n",
    "pseudonym_len = 28\n",
    "TX_length = int(packet*pseudonym_len)\n",
    "repeat = 10\n",
    "message = 'STOP' # This is our pseudonym message we transmit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "id": "2ab62694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_string(timestamp):\n",
    "    '''\n",
    "    Helper function to get data and time from timestamp\n",
    "    INPUT: timestamp\n",
    "    OUTPUT: data and time. Example: 01-04-2023, 19:50:27\n",
    "    '''\n",
    "    date_time = datetime.datetime.fromtimestamp(int(timestamp))\n",
    "    return date_time.strftime(\"%m-%d-%Y, %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "id": "992d842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def JsonLoad(folder, json_file):\n",
    "    '''\n",
    "    Load parameters from the saved json file\n",
    "    INPUT\n",
    "    ----\n",
    "        folder: path to the measurement folder. Example: \"SHOUT/Results/Shout_meas_01-04-2023_18-50-26\"\n",
    "        json_file: the json file with all the specifications. Example: '/save_iq_w_tx_gold.json'\n",
    "    OUTPUT\n",
    "    ----\n",
    "        samps_per_chip: samples per chip\n",
    "        wotxrepeat: number of repeating IQ sample collection w/o transmission. Used as an input to \n",
    "        traverse_dataset() func\n",
    "        rxrate: sampling rate at the receiver side\n",
    "    '''\n",
    "    #config_file = folder+'/'+json_file\n",
    "    #config_file = \"\"+\"/\"+str(folder)+\"/save_iq_w_tx_file.json\"\n",
    "    config_dict = json.load(open(json_file))[0]\n",
    "    nsamps = config_dict['nsamps']\n",
    "    rxrate = config_dict['rxrate']\n",
    "    rxfreq = config_dict['rxfreq']\n",
    "    wotxrepeat = config_dict['wotxrepeat']\n",
    "    rxrepeat = config_dict['rxrepeat']\n",
    "    txnodes = config_dict['txclients']\n",
    "    rxnodes = config_dict['rxclients']\n",
    "\n",
    "    return rxrepeat, rxrate, txnodes, rxnodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "id": "05dbd0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse_dataset(meas_folder):\n",
    "    '''\n",
    "    Load data from hdf5 format measurement file\n",
    "    INPUT\n",
    "    ----\n",
    "        meas_folder: path to the measurement folder. Example: \"SHOUT/Results/Shout_meas_01-04-2023_18-50-26\"\n",
    "    OUTPUT\n",
    "    ----\n",
    "        data: Collected IQ samples w/ transmission. It is indexed by the transmitter name\n",
    "        noise: Collected IQ samples w/o transmission. It is indexed by the transmitter name\n",
    "        txrxloc: transmitter and receiver names\n",
    "    '''\n",
    "    data = {}\n",
    "    noise = {}\n",
    "    txrxloc = {}\n",
    "\n",
    "    dataset = h5py.File(meas_folder + '/measurements.hdf5', \"r\") #meas_folder\n",
    "    #print(\"Dataset meta data:\", list(dataset.attrs.items()))\n",
    "    for cmd in dataset.keys():\n",
    "        #print(\"Command:\", cmd)\n",
    "        if cmd == 'saveiq':\n",
    "            cmd_time = list(dataset[cmd].keys())[0]\n",
    "           # print(\"  Timestamp:\", get_time_string(cmd_time))\n",
    "            #print(\"  Command meta data:\", list(dataset[cmd][cmd_time].attrs.items()))\n",
    "            for rx_gain in dataset[cmd][cmd_time].keys():\n",
    "               # print(\"   RX gain:\", rx_gain)\n",
    "                for rx in dataset[cmd][cmd_time][rx_gain].keys():\n",
    "                    print(\"\")\n",
    "                    #print(\"     RX:\", rx)\n",
    "                    #print(\"       Measurement items:\", list(dataset[cmd][cmd_time][rx_gain][rx].keys()))\n",
    "        elif cmd == 'saveiq_w_tx':\n",
    "            cmd_time = list(dataset[cmd].keys())[0]\n",
    "            #print(\"  Timestamp:\", get_time_string(cmd_time))\n",
    "            #print(\"  Command meta data:\", list(dataset[cmd][cmd_time].attrs.items()))\n",
    "            for tx in dataset[cmd][cmd_time].keys():\n",
    "                #print(\"   TX:\", tx)\n",
    "                \n",
    "                if tx == 'wo_tx':\n",
    "                    for rx_gain in dataset[cmd][cmd_time][tx].keys():\n",
    "                        #print(\"       RX gain:\", rx_gain)\n",
    "                       # print(dataset[cmd][cmd_time][tx][rx_gain].keys())\n",
    "                        for rx in dataset[cmd][cmd_time][tx][rx_gain].keys():\n",
    "                            #print(\"         RX:\", rx)\n",
    "                            #print(\"           Measurement items:\", list(dataset[cmd][cmd_time][tx][rx_gain][rx].keys()))\n",
    "                            repeat = np.shape(dataset[cmd][cmd_time][tx][rx_gain][rx]['rxsamples'])[0]\n",
    "                            #print(\"         repeat\", repeat)\n",
    "\n",
    "                            samplesNotx =  dataset[cmd][cmd_time][tx][rx_gain][rx]['rxsamples'][:repeat, :]\n",
    "                            namelist = rx.split('-')\n",
    "                            noise[namelist[1]] = samplesNotx\n",
    "                else:\n",
    "                    for tx_gain in dataset[cmd][cmd_time][tx].keys():\n",
    "                        #print(\"     TX gain:\", tx_gain)\n",
    "                        for rx_gain in dataset[cmd][cmd_time][tx][tx_gain].keys():\n",
    "                            #print(\"       RX gain:\", rx_gain)\n",
    "                            #print(dataset[cmd][cmd_time][tx][tx_gain][rx_gain].keys())\n",
    "                            for rx in dataset[cmd][cmd_time][tx][tx_gain][rx_gain].keys():\n",
    "                                repeat = np.shape(dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx]['rxsamples'])[0]\n",
    "                                #print(\"         RX:\", rx, \"; samples shape\", np.shape(dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx]['rxsamples']))\n",
    "                                #print(\"         Measurement items:\", list(dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx].keys()))\n",
    "                                # print(\"         rxloc\", (dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx]['rxloc'][0]))\n",
    "                                # peak avg check\n",
    "                                \n",
    "                                txrxloc.setdefault(tx, []).extend([rx]*repeat)\n",
    "                                rxsamples = dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx]['rxsamples'][:repeat, :]\n",
    "                                data.setdefault(tx, []).append(np.array(rxsamples))\n",
    "\n",
    "        else:                       \n",
    "            print('Unsupported command: ', cmd)\n",
    "\n",
    "    return data, noise, txrxloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "id": "b628d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURPOSE: perform preamble synchronization\n",
    "#          Uses the (complex-valued) preamble signal. The cross-correlation \n",
    "#          of the preamble signal and the received signal (at the time\n",
    "#          when the preamble is received) should have highest magnitude\n",
    "#          at the index delay where the preamble approximately starts.  \n",
    "# INPUT:   rx0: received signal (with a frequency offset)\n",
    "#          preambleSignal: complex, known, transmitted preamble signal \n",
    "# OUTPUT:  lagIndex: the index of rx0 where the preamble signal has highest \n",
    "#              cross-correlation\n",
    "#\n",
    "def crossCorrelationMax(rx0, preambleSignal):\n",
    "\n",
    "    # Cross correlate with the preamble to find it in the noisy signal\n",
    "    lags      = signal.correlation_lags(len(rx0), len(preambleSignal), mode='valid')\n",
    "    xcorr_out = signal.correlate(rx0, preambleSignal, mode='valid')\n",
    "    xcorr_mag = np.abs(xcorr_out)\n",
    "    # Don't let it sync to the end of the packet.\n",
    "    packetLenSamples = TX_length\n",
    "    maxIndex = np.argmax(xcorr_mag[:len(xcorr_mag)-packetLenSamples])\n",
    "    lagIndex = lags[maxIndex]\n",
    "\n",
    "    print('Max crosscorrelation with preamble at lag ' + str(lagIndex))\n",
    "\n",
    "    # Plot the selected signal.\n",
    "    plt.figure()\n",
    "    fig, subfigs = plt.subplots(2,1)\n",
    "    subfigs[0].plot(np.real(rx0), label='Real RX Signal')\n",
    "    subfigs[0].plot(np.imag(rx0), label='Imag RX Signal')\n",
    "    scale_factor = np.mean(np.abs(rx0))/np.mean(np.abs(preambleSignal))\n",
    "    subfigs[0].plot(range(lagIndex, lagIndex + len(preambleSignal)), scale_factor*np.real(preambleSignal), label='Preamble')\n",
    "    subfigs[0].legend()\n",
    "    subfigs[1].plot(lags, xcorr_mag, label='|X-Correlation|')\n",
    "    plt.xlabel('Sample Index', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return lagIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "id": "fdc19c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2bits(message):\n",
    "    # Convert to characters of '1' and '0' in a vector.\n",
    "    temp_message = []\n",
    "    final_message = []\n",
    "    for each in message:\n",
    "        temp_message.append(format(ord(each), '07b'))\n",
    "    for every in temp_message:\n",
    "        for digit in every:\n",
    "            final_message.append(int(digit))\n",
    "    return final_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1113,
   "id": "368ab8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binvector2str(binvector):\n",
    "    #binvector = binvector[0]\n",
    "    length = len(binvector)\n",
    "    eps = np.finfo('float').eps\n",
    "    if abs(length/7 - round(length/7)) > eps:\n",
    "        print('Length of bit stream must be a multiple of 7 to convert to a string.')\n",
    "    # Each character requires 7 bits in standard ASCII\n",
    "    num_characters = round(length/7)\n",
    "    # Maximum value is first in the vector. Otherwise would use 0:1:length-1\n",
    "    start = 6\n",
    "    bin_values = []\n",
    "    while start >= 0:\n",
    "        bin_values.append(int(math.pow(2,start)))\n",
    "        start = start - 1\n",
    "    bin_values = np.array(bin_values)\n",
    "    bin_values = np.transpose(bin_values)\n",
    "    str_out = '' # Initialize character vector\n",
    "    for i in range(num_characters):\n",
    "        single_char = binvector[i*7:i*7+7]\n",
    "        value = 0\n",
    "        for counter in range(len(single_char)):\n",
    "            value = value + (int(single_char[counter]) * int(bin_values[counter]))\n",
    "        str_out += chr(int(value))\n",
    "    return str_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "id": "d6a7a273-47a8-4db1-ab0b-13c33f9e2691",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hard Decision Algorithm\n",
    "## Make p-bit decisions by comparing patterns on bit-0 and bit-1\n",
    "## Trace changes in power with the p-bit and compare it with the known chip pattern.\n",
    "## This algorithm improves pseudonym detection in the presence of non-Gaussion type interferences\n",
    "\n",
    "def Matched_Filter_RF_Mitigation_Algorithm(x):\n",
    "    matching_filter0 =np.array([-1,1,-1,1,-1,1,-1,1,-1,1])\n",
    "    matching_filter1 =np.array([1,-1,1,-1,1,-1,1,-1,1,-1])\n",
    "    p_bit = []\n",
    "    for i in range(28):\n",
    "        pbit_data = x[i*packet:(i+1)*packet] # slices samples into one p-bit data = 6000 samples\n",
    "        \n",
    "        power = []\n",
    "        Cr = []       \n",
    "        threshold = 0.0\n",
    "        quantization_level = np.array([1,-1])\n",
    "        for j in range(10):\n",
    "            chip_data = pbit_data[j*samples:(j+1)*samples] # slice p-bit data into chip data = 600 samples\n",
    "            power.append(1000*sum(abs(chip_data)**2)/len(chip_data))\n",
    "\n",
    "\n",
    "        for k in range(1,10):\n",
    "\n",
    "            if power[k] > power[k-1]:\n",
    "                Cr.append(quantization_level[0])\n",
    "            else:\n",
    "                Cr.append(quantization_level[1]) \n",
    "\n",
    "        if np.dot(Cr,matching_filter1[1:]) >= np.dot(Cr,matching_filter0[1:]): # p-bit decision done by comparing p-bit powers with the threshold.\n",
    "            p_bit.append(1)\n",
    "        else:\n",
    "            p_bit.append(0) \n",
    "            \n",
    "    return np.array(p_bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "id": "ba556264-8cf4-4e81-addc-46fb697f246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Soft Decision Algorithm\n",
    "## Make p-bit decisions by comparing patterns on bit-0 and bit-1\n",
    "## Trace changes in power with the p-bit and compare it with the known chip pattern.\n",
    "## This algorithm improves pseudonym detection in the presence of non-Gaussion type interferences\n",
    "\n",
    "def Matched_Filter_Pseudonym_Detection_Algorithm(x):\n",
    "    matching_filter0 =np.array([-1,1,-1,1,-1,1,-1,1,-1,1])\n",
    "    matching_filter1 =np.array([1,-1,1,-1,1,-1,1,-1,1,-1])\n",
    "    p_bit = []\n",
    "    for i in range(28):\n",
    "        pbit_data = x[i*packet:(i+1)*packet] # slices samples into one p-bit data = 6000 samples\n",
    "        \n",
    "        power = []\n",
    "        Cr = []       \n",
    "        threshold = 0.0\n",
    "        quantization_level = np.array([1,-1])\n",
    "        for j in range(10):\n",
    "            chip_data = pbit_data[j*samples:(j+1)*samples] # slice p-bit data into chip data = 600 samples\n",
    "            power.append(1000*sum(abs(chip_data)**2)/len(chip_data))  \n",
    "        \n",
    "        if np.dot(power,matching_filter1) > np.dot(power,matching_filter0): # p-bit decision done by comparing p-bit powers with the threshold.\n",
    "            p_bit.append(1)\n",
    "        else:\n",
    "            p_bit.append(0)   \n",
    "    return np.array(p_bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "id": "5dcb671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "calculates the distance between the recoded pseudonym bits and the transmitted(true) pseudonym bits.\n",
    "'''\n",
    "def Distance(X,Y):\n",
    "    if len(X) != len(Y):\n",
    "        print('Warning: arrays have different dimensions')\n",
    "    count = 0\n",
    "    for i in range(len(X)):\n",
    "        if X[i]!= Y[i]:\n",
    "            count +=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "id": "4487aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Use preamble to estimate start of OFDM packet'''\n",
    "def Generate_HTSTF():\n",
    "    data = scipy.io.loadmat('HTSTF.mat')\n",
    "    new_data = data['stf'].reshape((1,len(data['stf'])))\n",
    "    preamble = np.tile(new_data,10)[0]\n",
    "    return preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "id": "f489ade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preambleSignal = Generate_HTSTF()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a1579",
   "metadata": {},
   "source": [
    "# Pseudonym Detection at Passive Receiver Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "id": "837635d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_Folders(x):\n",
    "    r = []\n",
    "    for root, dirs, files in os.walk(x):\n",
    "        r.append(dirs)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "id": "5db459a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Checks if pseudonyms are decoded correctly in each repeat of shout transmission.\n",
    "One experiment has 10 repeats.\n",
    "'''\n",
    "def Calculate_Eb_No_Passive(x):\n",
    "    \n",
    "    # Load parameters from the JSON file which describe what was measured\n",
    "    jsonfile = \"save_iq_w_tx_file.json\"\n",
    "    rxrepeat, samp_rate, txlocs, rxlocs = JsonLoad(x, jsonfile)\n",
    "    \n",
    "    # Load data from the HDF5 file, save IQ sample arrays\n",
    "    rx_data, rx_noise, txrxloc = traverse_dataset(x)\n",
    "    # samp_rate = 2e6\n",
    "\n",
    "    txloc = 'cbrssdr1-ustar-comp'\n",
    "    # rxloc = 'cbrssdr1-bes-comp'\n",
    "    rxloc = 'cbrssdr1-browning-comp'\n",
    "    #Calculate SNR\n",
    "    # Noise = rx_noise['bes'][0] \n",
    "    Noise = rx_noise['browning'][0]# measure the RX power while the TX is turned off\n",
    "    noise_power = np.mean(abs(Noise)**2)\n",
    "    \n",
    "    P_s = 0 #received power\n",
    "\n",
    "    for i in range(repeat):    \n",
    "        rx_data[txloc] = np.vstack(rx_data[txloc])\n",
    "        rxloc_arr = np.array(txrxloc[txloc])\n",
    "        rx0 = rx_data[txloc][rxloc_arr==rxloc][i]\n",
    "        \n",
    "        # synchronize pseudonym using preamble signal\n",
    "        lagIndex = crossCorrelationMax(rx0, preambleSignal)\n",
    "        start_of_data = lagIndex + len(preambleSignal)\n",
    "        \n",
    "        Rx_signal = rx0[start_of_data:TX_length+start_of_data]\n",
    "       \n",
    "        P_s += np.mean(abs(Rx_signal)**2) \n",
    "    return P_s/repeat, noise_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1123,
   "id": "10e49884",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Checks if pseudonyms are decoded correctly in each repeat of shout transmission.\n",
    "One experiment has 10 repeats.\n",
    "'''\n",
    "\n",
    "def Calculate_Pseudonym_BER(x):\n",
    "    # Load parameters from the JSON file which describe what was measured\n",
    " \n",
    "    #folder = x\n",
    "    jsonfile = \"save_iq_w_tx_file.json\"\n",
    "    rxrepeat, samp_rate, txlocs, rxlocs = JsonLoad(x, jsonfile)\n",
    "    # Load data from the HDF5 file, save IQ sample arrays\n",
    "    rx_data, rx_noise, txrxloc = traverse_dataset(x)\n",
    "#     samp_rate = 2e6\n",
    "\n",
    "    txloc = 'cbrssdr1-ustar-comp'\n",
    "    # rxloc = 'cbrssdr1-bes-comp'\n",
    "    rxloc = 'cbrssdr1-browning-comp'\n",
    "    # initialize error\n",
    "    pseudonym_BER = 0\n",
    "    P_s = 0\n",
    "    count = 0\n",
    "    for i in range(repeat):    \n",
    "        rx_data[txloc] = np.vstack(rx_data[txloc])\n",
    "        rxloc_arr = np.array(txrxloc[txloc])\n",
    "        rx0 = rx_data[txloc][rxloc_arr==rxloc][i]\n",
    "        \n",
    "        # synchronize pseudonym using preamble signal\n",
    "        lagIndex = crossCorrelationMax(rx0, preambleSignal)\n",
    "        start_of_data = lagIndex + len(preambleSignal)\n",
    "        Rx_signal = rx0[start_of_data:TX_length+start_of_data]\n",
    "\n",
    "        estimate_pseudonym = Matched_Filter_RF_Mitigation_Algorithm2(Rx_signal)\n",
    "        print(binvector2str(estimate_pseudonym))\n",
    "\n",
    "        pseudonym_BER += Distance(text2bits('STOP'),estimate_pseudonym)\n",
    "    return pseudonym_BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "id": "40f28914",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Computes the average pseudonym error in the experiment.\n",
    "Experiment data is stored in folders that contain 10 repeats each.\n",
    "'''\n",
    "def Probability_Pseudonym_Detection(x):\n",
    "    folders = Extract_Folders(x)[0]\n",
    "    num_folder = len(folders)\n",
    "    pseudonym_BER = 0\n",
    "    signal = 0\n",
    "    noise = 0\n",
    "    noise_power = []\n",
    "    signal_power = []\n",
    "    for i in range(len(folders)):\n",
    "        s,n = Calculate_Eb_No_Passive(x + '/'+folders[i])\n",
    "        noise_power.append(n)\n",
    "        signal_power.append(s)\n",
    "        signal += s\n",
    "        noise += n\n",
    "    Eb_No = 10*(np.log10(0.5*(signal-noise)/noise))\n",
    "\n",
    "    # plt.plot(noise_power)\n",
    "    # plt.show()\n",
    "    # plt.plot(signal_power)\n",
    "    # plt.show()\n",
    "    print('The SNR at the Passive RX is:',round(Eb_No,2), 'dB \\n')\n",
    "\n",
    "    for i in range(len(folders)):\n",
    "        print(folders[i])\n",
    "        BER = Calculate_Pseudonym_BER(x + '/'+folders[i])\n",
    "        pseudonym_BER += BER\n",
    "    \n",
    "    p_bit_error = pseudonym_BER/(num_folder*repeat*pseudonym_len)\n",
    "    return p_bit_error, Eb_No"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c675f5ed",
   "metadata": {},
   "source": [
    "# Results Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535a4dca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Probability_Pseudonym_Detection(\"-13dB_03\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
