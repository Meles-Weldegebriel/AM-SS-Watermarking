{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6bb419c",
   "metadata": {},
   "source": [
    "# AM-SS Data Demodulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "fb307f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import datetime\n",
    "import scipy.signal as signal\n",
    "#import pandas as pd\n",
    "#import seaborn as sns\n",
    "import statistics as stats\n",
    "import os\n",
    "import scipy.io\n",
    "import h5py\n",
    "# from scipy.spatial.distance import hamming\n",
    "# from time import sleep\n",
    "\n",
    "rc('xtick', labelsize=14) \n",
    "rc('ytick', labelsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "ad67a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Protocol parameters!!!\n",
    "'''\n",
    "packet = 6000\n",
    "samples = 600\n",
    "pseudonym_len = 28\n",
    "TX_length = 11200\n",
    "repeat = 10\n",
    "message = 'STOP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "2ab62694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_string(timestamp):\n",
    "    '''\n",
    "    Helper function to get data and time from timestamp\n",
    "    INPUT: timestamp\n",
    "    OUTPUT: data and time. Example: 01-04-2023, 19:50:27\n",
    "    '''\n",
    "    date_time = datetime.datetime.fromtimestamp(int(timestamp))\n",
    "    return date_time.strftime(\"%m-%d-%Y, %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "992d842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def JsonLoad(folder, json_file):\n",
    "    '''\n",
    "    Load parameters from the saved json file\n",
    "    INPUT\n",
    "    ----\n",
    "        folder: path to the measurement folder. Example: \"SHOUT/Results/Shout_meas_01-04-2023_18-50-26\"\n",
    "        json_file: the json file with all the specifications. Example: '/save_iq_w_tx_gold.json'\n",
    "    OUTPUT\n",
    "    ----\n",
    "        samps_per_chip: samples per chip\n",
    "        wotxrepeat: number of repeating IQ sample collection w/o transmission. Used as an input to \n",
    "        traverse_dataset() func\n",
    "        rxrate: sampling rate at the receiver side\n",
    "    '''\n",
    "    #config_file = folder+'/'+json_file\n",
    "    #config_file = \"\"+\"/\"+str(folder)+\"/save_iq_w_tx_file.json\"\n",
    "    config_dict = json.load(open(json_file))[0]\n",
    "    nsamps = config_dict['nsamps']\n",
    "    rxrate = config_dict['rxrate']\n",
    "    rxfreq = config_dict['rxfreq']\n",
    "    wotxrepeat = config_dict['wotxrepeat']\n",
    "    rxrepeat = config_dict['rxrepeat']\n",
    "    txnodes = config_dict['txclients']\n",
    "    rxnodes = config_dict['rxclients']\n",
    "\n",
    "    return rxrepeat, rxrate, txnodes, rxnodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "05dbd0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse_dataset(meas_folder):\n",
    "    '''\n",
    "    Load data from hdf5 format measurement file\n",
    "    INPUT\n",
    "    ----\n",
    "        meas_folder: path to the measurement folder. Example: \"SHOUT/Results/Shout_meas_01-04-2023_18-50-26\"\n",
    "    OUTPUT\n",
    "    ----\n",
    "        data: Collected IQ samples w/ transmission. It is indexed by the transmitter name\n",
    "        noise: Collected IQ samples w/o transmission. It is indexed by the transmitter name\n",
    "        txrxloc: transmitter and receiver names\n",
    "    '''\n",
    "    data = {}\n",
    "    noise = {}\n",
    "    txrxloc = {}\n",
    "\n",
    "    dataset = h5py.File(meas_folder + '/measurements.hdf5', \"r\") #meas_folder\n",
    "    #print(\"Dataset meta data:\", list(dataset.attrs.items()))\n",
    "    for cmd in dataset.keys():\n",
    "        #print(\"Command:\", cmd)\n",
    "        if cmd == 'saveiq':\n",
    "            cmd_time = list(dataset[cmd].keys())[0]\n",
    "           # print(\"  Timestamp:\", get_time_string(cmd_time))\n",
    "            #print(\"  Command meta data:\", list(dataset[cmd][cmd_time].attrs.items()))\n",
    "            for rx_gain in dataset[cmd][cmd_time].keys():\n",
    "               # print(\"   RX gain:\", rx_gain)\n",
    "                for rx in dataset[cmd][cmd_time][rx_gain].keys():\n",
    "                    print(\"\")\n",
    "                    #print(\"     RX:\", rx)\n",
    "                    #print(\"       Measurement items:\", list(dataset[cmd][cmd_time][rx_gain][rx].keys()))\n",
    "        elif cmd == 'saveiq_w_tx':\n",
    "            cmd_time = list(dataset[cmd].keys())[0]\n",
    "            #print(\"  Timestamp:\", get_time_string(cmd_time))\n",
    "            #print(\"  Command meta data:\", list(dataset[cmd][cmd_time].attrs.items()))\n",
    "            for tx in dataset[cmd][cmd_time].keys():\n",
    "                #print(\"   TX:\", tx)\n",
    "                \n",
    "                if tx == 'wo_tx':\n",
    "                    for rx_gain in dataset[cmd][cmd_time][tx].keys():\n",
    "                        #print(\"       RX gain:\", rx_gain)\n",
    "                       # print(dataset[cmd][cmd_time][tx][rx_gain].keys())\n",
    "                        for rx in dataset[cmd][cmd_time][tx][rx_gain].keys():\n",
    "                            #print(\"         RX:\", rx)\n",
    "                            #print(\"           Measurement items:\", list(dataset[cmd][cmd_time][tx][rx_gain][rx].keys()))\n",
    "                            repeat = np.shape(dataset[cmd][cmd_time][tx][rx_gain][rx]['rxsamples'])[0]\n",
    "                            #print(\"         repeat\", repeat)\n",
    "\n",
    "                            samplesNotx =  dataset[cmd][cmd_time][tx][rx_gain][rx]['rxsamples'][:repeat, :]\n",
    "                            namelist = rx.split('-')\n",
    "                            noise[namelist[1]] = samplesNotx\n",
    "                else:\n",
    "                    for tx_gain in dataset[cmd][cmd_time][tx].keys():\n",
    "                        #print(\"     TX gain:\", tx_gain)\n",
    "                        for rx_gain in dataset[cmd][cmd_time][tx][tx_gain].keys():\n",
    "                            #print(\"       RX gain:\", rx_gain)\n",
    "                            #print(dataset[cmd][cmd_time][tx][tx_gain][rx_gain].keys())\n",
    "                            for rx in dataset[cmd][cmd_time][tx][tx_gain][rx_gain].keys():\n",
    "                                repeat = np.shape(dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx]['rxsamples'])[0]\n",
    "                                #print(\"         RX:\", rx, \"; samples shape\", np.shape(dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx]['rxsamples']))\n",
    "                                #print(\"         Measurement items:\", list(dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx].keys()))\n",
    "                                # print(\"         rxloc\", (dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx]['rxloc'][0]))\n",
    "                                # peak avg check\n",
    "                                \n",
    "                                txrxloc.setdefault(tx, []).extend([rx]*repeat)\n",
    "                                rxsamples = dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx]['rxsamples'][:repeat, :]\n",
    "                                data.setdefault(tx, []).append(np.array(rxsamples))\n",
    "\n",
    "        else:                       \n",
    "            print('Unsupported command: ', cmd)\n",
    "\n",
    "    return data, noise, txrxloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "b628d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURPOSE: perform preamble synchronization\n",
    "#          Uses the (complex-valued) preamble signal. The cross-correlation \n",
    "#          of the preamble signal and the received signal (at the time\n",
    "#          when the preamble is received) should have highest magnitude\n",
    "#          at the index delay where the preamble approximately starts.  \n",
    "# INPUT:   rx0: received signal (with a frequency offset)\n",
    "#          preambleSignal: complex, known, transmitted preamble signal \n",
    "# OUTPUT:  lagIndex: the index of rx0 where the preamble signal has highest \n",
    "#              cross-correlation\n",
    "#\n",
    "def crossCorrelationMax(rx0, preambleSignal):\n",
    "\n",
    "    # Cross correlate with the preamble to find it in the noisy signal\n",
    "    lags      = signal.correlation_lags(len(rx0), len(preambleSignal), mode='valid')\n",
    "    xcorr_out = signal.correlate(rx0, preambleSignal, mode='valid')\n",
    "    xcorr_mag = np.abs(xcorr_out)\n",
    "    # Don't let it sync to the end of the packet.\n",
    "    packetLenSamples = 168800\n",
    "    maxIndex = np.argmax(xcorr_mag[:len(xcorr_mag)-packetLenSamples])\n",
    "    lagIndex = lags[maxIndex]\n",
    "\n",
    "    #print('Max crosscorrelation with preamble at lag ' + str(lagIndex))\n",
    "\n",
    "    # # Plot the selected signal.\n",
    "    # plt.figure()\n",
    "    # fig, subfigs = plt.subplots(2,1)\n",
    "    # subfigs[0].plot(np.real(rx0), label='Real RX Signal')\n",
    "    # subfigs[0].plot(np.imag(rx0), label='Imag RX Signal')\n",
    "    # scale_factor = np.mean(np.abs(rx0))/np.mean(np.abs(preambleSignal))\n",
    "    # subfigs[0].plot(range(lagIndex, lagIndex + len(preambleSignal)), scale_factor*np.real(preambleSignal), label='Preamble')\n",
    "    # subfigs[0].legend()\n",
    "    # subfigs[1].plot(lags, xcorr_mag, label='|X-Correlation|')\n",
    "    # plt.xlabel('Sample Index', fontsize=14)\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    return lagIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "fdc19c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2bits(message):\n",
    "    # Convert to characters of '1' and '0' in a vector.\n",
    "    temp_message = []\n",
    "    final_message = []\n",
    "    for each in message:\n",
    "        temp_message.append(format(ord(each), '07b'))\n",
    "    for every in temp_message:\n",
    "        for digit in every:\n",
    "            final_message.append(int(digit))\n",
    "    return final_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "368ab8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binvector2str(binvector):\n",
    "    #binvector = binvector[0]\n",
    "    length = len(binvector)\n",
    "    eps = np.finfo('float').eps\n",
    "    if abs(length/7 - round(length/7)) > eps:\n",
    "        print('Length of bit stream must be a multiple of 7 to convert to a string.')\n",
    "    # Each character requires 7 bits in standard ASCII\n",
    "    num_characters = round(length/7)\n",
    "    # Maximum value is first in the vector. Otherwise would use 0:1:length-1\n",
    "    start = 6\n",
    "    bin_values = []\n",
    "    while start >= 0:\n",
    "        bin_values.append(int(math.pow(2,start)))\n",
    "        start = start - 1\n",
    "    bin_values = np.array(bin_values)\n",
    "    bin_values = np.transpose(bin_values)\n",
    "    str_out = '' # Initialize character vector\n",
    "    for i in range(num_characters):\n",
    "        single_char = binvector[i*7:i*7+7]\n",
    "        value = 0\n",
    "        for counter in range(len(single_char)):\n",
    "            value = value + (int(single_char[counter]) * int(bin_values[counter]))\n",
    "        str_out += chr(int(value))\n",
    "    return str_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "5dcb671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "calculates the distance between the recoded pseudonym bits and the transmitted(true) pseudonym bits.\n",
    "'''\n",
    "def Distance(X,Y):\n",
    "    if len(X) != len(Y):\n",
    "        print('Warning: arrays have different dimensions')\n",
    "    count = 0\n",
    "    for i in range(len(X)):\n",
    "        if X[i]!= Y[i]:\n",
    "            count +=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "4487aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Use preamble to estimate start of OFDM packet'''\n",
    "def Generate_HTSTF():\n",
    "    data = scipy.io.loadmat('HTSTF.mat')\n",
    "    new_data = data['stf'].reshape((1,len(data['stf'])))\n",
    "    preamble = np.tile(new_data,10)[0]\n",
    "    return preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "f489ade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preambleSignal = Generate_HTSTF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "837635d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_Folders(x):\n",
    "    r = []\n",
    "    for root, dirs, files in os.walk(x):\n",
    "        r.append(dirs)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "5db459a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Checks if pseudonyms are decoded correctly in each repeat of shout transmission.\n",
    "One experiment has 10 repeats.\n",
    "'''\n",
    "def Calculate_Eb_No_Passive(x):\n",
    "    \n",
    "    # Load parameters from the JSON file which describe what was measured\n",
    "    jsonfile = \"save_iq_w_tx_file.json\"\n",
    "    rxrepeat, samp_rate, txlocs, rxlocs = JsonLoad(x, jsonfile)\n",
    "    \n",
    "    # Load data from the HDF5 file, save IQ sample arrays\n",
    "    rx_data, rx_noise, txrxloc = traverse_dataset(x)\n",
    "    # samp_rate = 2e6\n",
    "\n",
    "    txloc = 'cbrssdr1-ustar-comp'\n",
    "    rxloc = 'cbrssdr1-browning-comp'\n",
    "\n",
    "    #Calculate SNR\n",
    "    Noise = rx_noise['browning'][0]  # measure the RX power while the TX is turned off\n",
    "    noise_power = np.mean(abs(Noise)**2)\n",
    "    \n",
    "    P_s = 0 #received power\n",
    "\n",
    "    for i in range(repeat):    \n",
    "        rx_data[txloc] = np.vstack(rx_data[txloc])\n",
    "        rxloc_arr = np.array(txrxloc[txloc])\n",
    "        rx0 = rx_data[txloc][rxloc_arr==rxloc][i]\n",
    "        \n",
    "        # synchronize pseudonym using preamble signal\n",
    "        lagIndex = crossCorrelationMax(rx0, preambleSignal)\n",
    "        start_of_data = lagIndex + len(preambleSignal)\n",
    "        \n",
    "        Rx_signal = rx0[start_of_data:TX_length+start_of_data]\n",
    "       \n",
    "        P_s += np.mean(abs(Rx_signal)**2) \n",
    "    return P_s/repeat, noise_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "10e49884",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Checks if pseudonyms are decoded correctly in each repeat of shout transmission.\n",
    "One experiment has 10 repeats.\n",
    "'''\n",
    "\n",
    "def Calculate_Pseudonym_BER(x):\n",
    "    # Load parameters from the JSON file which describe what was measured\n",
    " \n",
    "    #folder = x\n",
    "    jsonfile = \"save_iq_w_tx_file.json\"\n",
    "    rxrepeat, samp_rate, txlocs, rxlocs = JsonLoad(x, jsonfile)\n",
    "    # Load data from the HDF5 file, save IQ sample arrays\n",
    "    rx_data, rx_noise, txrxloc = traverse_dataset(x)\n",
    "#     samp_rate = 2e6\n",
    "\n",
    "    txloc = 'cbrssdr1-ustar-comp'\n",
    "    rxloc = 'cbrssdr1-browning-comp'\n",
    "    # rxloc = 'cbrssdr1-browning-comp'\n",
    "    # initialize error\n",
    "    pseudonym_BER = 0\n",
    "    P_s = 0\n",
    "    count = 0\n",
    "    for i in range(repeat):    \n",
    "        rx_data[txloc] = np.vstack(rx_data[txloc])\n",
    "        rxloc_arr = np.array(txrxloc[txloc])\n",
    "        rx0 = rx_data[txloc][rxloc_arr==rxloc][i]\n",
    "        \n",
    "        # synchronize pseudonym using preamble signal\n",
    "        lagIndex = crossCorrelationMax(rx0, preambleSignal)\n",
    "        start_of_data = lagIndex + len(preambleSignal)\n",
    "        Rx_signal = rx0[start_of_data:TX_length+start_of_data]\n",
    "\n",
    "        estimate_pseudonym = Matched_Filter_Pseudonym_Detection_Algorithm(Rx_signal)\n",
    "        print(binvector2str(estimate_pseudonym))\n",
    "\n",
    "        pseudonym_BER += Distance(text2bits('STOP'),estimate_pseudonym)\n",
    "    return pseudonym_BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "f318b19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load collected IQ samples from file\n",
    "def readCom(file_path):\n",
    "    return np.fromfile(file_path, dtype=np.complex64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "40f28914",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Computes the average pseudonym error in the experiment.\n",
    "Experiment data is stored in folders that contain 10 repeats each.\n",
    "'''\n",
    "def Probability_Pseudonym_Detection(x):\n",
    "    folders = Extract_Folders(x)[0]\n",
    "    num_folder = len(folders)\n",
    "    pseudonym_BER = 0\n",
    "    signal = 0\n",
    "    noise = 0\n",
    "    noise_power = []\n",
    "    signal_power = []\n",
    "    for i in range(len(folders)):\n",
    "        s,n = Calculate_Eb_No_Passive(x + '/'+folders[i])\n",
    "        noise_power.append(n)\n",
    "        signal_power.append(s)\n",
    "        signal += s\n",
    "        noise += n\n",
    "    Eb_No = 10*(np.log10(0.5*(signal-noise)/noise))\n",
    "\n",
    "    plt.plot(noise_power)\n",
    "    plt.show()\n",
    "    plt.plot(signal_power)\n",
    "    plt.show()\n",
    "    print('The SNR at the Passive RX is:',round(Eb_No,2), 'dB \\n')\n",
    "\n",
    "    for i in range(len(folders)):\n",
    "\n",
    "        BER = Calculate_Pseudonym_BER(x + '/'+folders[i])\n",
    "        pseudonym_BER += BER\n",
    "    \n",
    "    p_bit_error = pseudonym_BER/(num_folder*repeat*pseudonym_len)\n",
    "    return p_bit_error, Eb_No"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5797749",
   "metadata": {},
   "source": [
    "# OFDM Data Demodulation at Intended Receiver Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "4b677f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Protocol parameters!!!\n",
    "'''\n",
    "FFT = 64 # FFT size for extracting IQ sample in each subcarrier\n",
    "OFDM_size = 80 # OFDM symbol with cyclic prefix\n",
    "data_size = 48 # data_subcarriers\n",
    "mess_length = 560\n",
    "actual_message='I have worked in SPAN Lab for the last three & half years.I implemented Pseudonymetry in POWDER.'\n",
    "num_bits = 672"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "bb2ff76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CP = 16  # 25% cyclic prefix\n",
    "pilotValue = 3+3j # known values for pilots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "f3000b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCarriers = np.arange(FFT)  # indices of all subcarriers ([0, 1, ... K-1])\n",
    "pilotCarriers = np.array([7,21,36,50]) # Pilots indices.\n",
    "guardCarriers = np.array([0,1,2,3,4,5,58,59,60,61,62,63]) # 6 subcarrier guard bands on each side\n",
    "nondataCarriers = np.concatenate([pilotCarriers,guardCarriers])\n",
    "dataCarriers = np.delete(allCarriers, nondataCarriers) # data carriers are allCarriers -(pilot+guard carriers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "e62bcf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Convert M-ary data to binary data\n",
    "#          each m-ary value input in \"data\" is converted to\n",
    "#          log2(M) binary values.\n",
    "# INPUT: M-ary digit vector\n",
    "# OUTPUT: Binary digit vector, with length equal to the number\n",
    "#         of values in data multiplied by log2(M)\n",
    "def mary2binary(data, M):\n",
    "    length = len(data) # number of values in data\n",
    "    log2M = round(np.log2(M)) # integer number of bits per data value\n",
    "    format_string = '0' + str(log2M) + 'b'\n",
    "    binarydata = np.zeros((1,length*log2M))\n",
    "    count = 0\n",
    "    for each in data:\n",
    "        binval = format(int(each), format_string)\n",
    "        for i in range(log2M):\n",
    "            binarydata[0][count+i] = int(binval[i])\n",
    "        count = count + log2M\n",
    "    return binarydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "1962f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURPOSE: Find the symbols which are closest in the complex plane \n",
    "#          to the measured complex received signal values.\n",
    "# INPUT:   Received r_hat values (output of matched filter downsampled),\n",
    "#          and possible signal space complex values. \n",
    "# OUTPUT:  m-ary symbol indices in 0...length(outputVec)-1\n",
    "def findClosestComplex(r_hat, outputVec):\n",
    "    # outputVec is a 4-length vector for QPSK, would be M for M-QAM or M-PSK.\n",
    "    # This checks, one symbol sample at a time,  which complex symbol value\n",
    "    # is closest in the complex plane.\n",
    "    data_out = [np.argmin(np.abs(r-outputVec)) for r in r_hat]\n",
    "    return data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "3924f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Channel_Estimation(x):\n",
    "    pilots = x[pilotCarriers] \n",
    "    H_at_pilots = pilots / pilotValue \n",
    "    \n",
    "    # Perform interpolation between the pilot carriers to get an estimate of the channel in the data carriers. \n",
    "    H_abs=scipy.interpolate.interp1d(pilotCarriers, abs(H_at_pilots), kind='nearest', fill_value='extrapolate')(allCarriers)\n",
    "    H_phase = scipy.interpolate.interp1d(pilotCarriers, np.angle(H_at_pilots), kind='nearest',fill_value = 'extrapolate')(allCarriers)\n",
    "    H_estimate = H_abs * np.exp(1j*H_phase)\n",
    "    \n",
    "    return H_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "75d405f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Equalization(OFDM_demod, Hest):\n",
    "    return OFDM_demod / Hest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "f0118212",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''PURPOSE: To recover the data signal'''\n",
    "def OFDM_RX(data):\n",
    "    for i in range(len(data)//(OFDM_size)):\n",
    "        data_cp = data[i*(OFDM_size):(i+1)*(OFDM_size)]\n",
    "        data_without_cp = data_cp[CP:]\n",
    "        \n",
    "        # Generate frequency domain signal\n",
    "        OFDM_freq = np.fft.fft(data_without_cp,n=FFT)\n",
    "        \n",
    "        H_est = Channel_Estimation(OFDM_freq) # estimate the channel\n",
    "        \n",
    "        OFDM_est = Equalization(OFDM_freq,H_est) # sub-carrier equalization\n",
    "        \n",
    "        OFDM_data = OFDM_est[dataCarriers] # extract the data signal\n",
    "        if i == 0:\n",
    "            OFDM_swap =  OFDM_data\n",
    "        else:\n",
    "            OFDM_signal = np.concatenate((OFDM_swap,  OFDM_data))\n",
    "            OFDM_swap = OFDM_signal\n",
    "    return OFDM_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "6872c93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QPSK_Data_Demodulation(x):\n",
    "    outputVec = np.array([1+1j, -1+1j, 1-1j, -1-1j])\n",
    "    data_error = 0.0\n",
    "    for i in range(len(x)//mess_length):\n",
    "        time_signal = x[i*mess_length:(i+1)*mess_length]\n",
    "        detected_signal = OFDM_RX(time_signal)\n",
    "       \n",
    "        mary_out  = findClosestComplex(detected_signal, outputVec)\n",
    "        data_bits  = mary2binary(mary_out, 4)[0]\n",
    "        data_error += Distance(data_bits,text2bits(actual_message))\n",
    "        # print(binvector2str(data_bits))\n",
    "    return data_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "31d1e109-1722-4e74-a38b-8888de600d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Checks if pseudonyms are decoded correctly in each repeat of shout transmission.\n",
    "One experiment has 10 repeats.\n",
    "'''\n",
    "def Calculate_Eb_No_Intended(x):\n",
    "    # Load parameters from the JSON file which describe what was measured\n",
    " \n",
    "    #folder = x\n",
    "    jsonfile = \"save_iq_w_tx_file.json\"\n",
    "    rxrepeat, samp_rate, txlocs, rxlocs = JsonLoad(x, jsonfile)\n",
    "    # Load data from the HDF5 file, save IQ sample arrays\n",
    "    rx_data, rx_noise, txrxloc = traverse_dataset(x)\n",
    "    samp_rate = 2e6\n",
    "\n",
    "    txloc = 'cbrssdr1-ustar-comp'# select the TX\n",
    "    rxloc = 'cbrssdr1-meb-comp' # select the RX\n",
    "    # rxloc = 'cbrssdr1-browning-comp'\n",
    "    \n",
    "    #Calculate SNR\n",
    "    Noise = rx_noise['meb'][0]\n",
    "    # Noise = rx_noise['browning'][0]  # measure the RX power while the TX is turned off\n",
    "    noise_power = np.mean(abs(Noise)**2)\n",
    "    \n",
    "    # initialize error\n",
    "    \n",
    "    P_s = 0\n",
    "\n",
    "    for i in range(repeat):    \n",
    "        repNum = i\n",
    "        rx_data[txloc] = np.vstack(rx_data[txloc])\n",
    "        rxloc_arr = np.array(txrxloc[txloc])\n",
    "        rx0 = rx_data[txloc][rxloc_arr==rxloc][repNum]\n",
    "        \n",
    "        # synchronize pseudonym using preamble signal\n",
    "        lagIndex = crossCorrelationMax(rx0, preambleSignal)\n",
    "        start_of_data = lagIndex + len(preambleSignal)\n",
    "        Rx_signal = rx0[start_of_data:TX_length+start_of_data]\n",
    "\n",
    "       \n",
    "        P_s += np.mean(abs(Rx_signal)**2)\n",
    "\n",
    "    signal_power = P_s/repeat   \n",
    "    return signal_power, noise_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "a4f407d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Checks if data bits are decoded correctly in each repeat of shout transmission.\n",
    "One experiment has 10 repeats.\n",
    "'''\n",
    "\n",
    "def Calculate_Data_BER(x):\n",
    "    # Load parameters from the JSON file which describe what was measured\n",
    "\n",
    "    jsonfile = \"save_iq_w_tx_file.json\"\n",
    "    rxrepeat, samp_rate, txlocs, rxlocs = JsonLoad(x, jsonfile)\n",
    "    # Load data from the HDF5 file, save IQ sample arrays\n",
    "    rx_data, rx_noise, txrxloc = traverse_dataset(x)\n",
    "#     samp_rate = 2e6\n",
    "\n",
    "    txloc = 'cbrssdr1-ustar-comp'\n",
    "    rxloc = 'cbrssdr1-meb-comp'\n",
    "    # rxloc = 'cbrssdr1-browning-comp'\n",
    "\n",
    "    # initialize error\n",
    "    data_BER = 0.0\n",
    "    \n",
    "    for i in range(repeat):    \n",
    "        rx_data[txloc] = np.vstack(rx_data[txloc])\n",
    "        rxloc_arr = np.array(txrxloc[txloc])\n",
    "        rx0 = rx_data[txloc][rxloc_arr==rxloc][i]\n",
    "        \n",
    "        # synchronize pseudonym using preamble signal\n",
    "        lagIndex = crossCorrelationMax(rx0, preambleSignal)\n",
    "        start_of_data = lagIndex + len(preambleSignal)\n",
    "        Rx_signal = rx0[start_of_data:TX_length+start_of_data]\n",
    "\n",
    "        data_BER += QPSK_Data_Demodulation(Rx_signal) \n",
    "        \n",
    "    return data_BER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "798267e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Computes the average data bit error in the experiment.\n",
    "Experiment data is stored in folders that contain 10 repeats each.\n",
    "'''\n",
    "def Probability_Data_Demodulation(x):\n",
    "    folders = Extract_Folders(x)[0]\n",
    "    num_folder = len(folders)\n",
    "    Data_BER = 0\n",
    "    signal = 0\n",
    "    noise = 0\n",
    "    noise_power = []\n",
    "    signal_power = []\n",
    "    for i in range(len(folders)):\n",
    "        print(folders[i])\n",
    "        s,n = Calculate_Eb_No_Intended(x + '/'+folders[i])\n",
    "        noise_power.append(n)\n",
    "        signal_power.append(s)\n",
    "        signal += s\n",
    "        noise += n\n",
    "    Eb_No = 10*(np.log10(0.5*(signal-noise)/noise))\n",
    "    \n",
    "    print('The SNR at the intended RX is:',round(Eb_No,2), 'dB \\n')\n",
    "\n",
    "    for i in range(len(folders)):\n",
    "        Data_BER += Calculate_Data_BER(x + '/'+folders[i])\n",
    "    \n",
    "    d_bit_error = Data_BER/(num_folder*repeat*num_bits*300)\n",
    "    return d_bit_error, Eb_No "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c675f5ed",
   "metadata": {},
   "source": [
    "# Results Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "50566cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Probability_Data_Demodulation(\"data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
