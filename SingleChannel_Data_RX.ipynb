{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6bb419c",
   "metadata": {},
   "source": [
    "## Pseudonym error performance under multiple interference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9883,
   "id": "fb307f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "import statistics as stats\n",
    "import scipy.io\n",
    "from scipy.spatial.distance import hamming\n",
    "import os\n",
    "\n",
    "rc('xtick', labelsize=14) \n",
    "rc('ytick', labelsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9884,
   "id": "2ab62694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_string(timestamp):\n",
    "    '''\n",
    "    Helper function to get data and time from timestamp\n",
    "    INPUT: timestamp\n",
    "    OUTPUT: data and time. Example: 01-04-2023, 19:50:27\n",
    "    '''\n",
    "    date_time = datetime.datetime.fromtimestamp(int(timestamp))\n",
    "    return date_time.strftime(\"%m-%d-%Y, %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9885,
   "id": "992d842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def JsonLoad(folder, json_file):\n",
    "    '''\n",
    "    Load parameters from the saved json file\n",
    "    INPUT\n",
    "    ----\n",
    "        folder: path to the measurement folder. Example: \"SHOUT/Results/Shout_meas_01-04-2023_18-50-26\"\n",
    "        json_file: the json file with all the specifications. Example: '/save_iq_w_tx_gold.json'\n",
    "    OUTPUT\n",
    "    ----\n",
    "        samps_per_chip: samples per chip\n",
    "        wotxrepeat: number of repeating IQ sample collection w/o transmission. Used as an input to \n",
    "        traverse_dataset() func\n",
    "        rxrate: sampling rate at the receiver side\n",
    "    '''\n",
    "    #config_file = folder+'/'+json_file\n",
    "    #config_file = \"\"+\"/\"+str(folder)+\"/save_iq_w_tx_file.json\"\n",
    "    config_dict = json.load(open(json_file))[0]\n",
    "    nsamps = config_dict['nsamps']\n",
    "    rxrate = config_dict['rxrate']\n",
    "    rxfreq = config_dict['rxfreq']\n",
    "    wotxrepeat = config_dict['wotxrepeat']\n",
    "    rxrepeat = config_dict['rxrepeat']\n",
    "    txnodes = config_dict['txclients']\n",
    "    rxnodes = config_dict['rxclients']\n",
    "\n",
    "    return rxrepeat, rxrate, txnodes, rxnodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9886,
   "id": "05dbd0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse_dataset(meas_folder):\n",
    "    '''\n",
    "    Load data from hdf5 format measurement file\n",
    "    INPUT\n",
    "    ----\n",
    "        meas_folder: path to the measurement folder. Example: \"SHOUT/Results/Shout_meas_01-04-2023_18-50-26\"\n",
    "    OUTPUT\n",
    "    ----\n",
    "        data: Collected IQ samples w/ transmission. It is indexed by the transmitter name\n",
    "        noise: Collected IQ samples w/o transmission. It is indexed by the transmitter name\n",
    "        txrxloc: transmitter and receiver names\n",
    "    '''\n",
    "    data = {}\n",
    "    noise = {}\n",
    "    txrxloc = {}\n",
    "\n",
    "    dataset = h5py.File(meas_folder + '/measurements.hdf5', \"r\") #meas_folder\n",
    "    #print(\"Dataset meta data:\", list(dataset.attrs.items()))\n",
    "    for cmd in dataset.keys():\n",
    "        #print(\"Command:\", cmd)\n",
    "        if cmd == 'saveiq':\n",
    "            cmd_time = list(dataset[cmd].keys())[0]\n",
    "           # print(\"  Timestamp:\", get_time_string(cmd_time))\n",
    "            #print(\"  Command meta data:\", list(dataset[cmd][cmd_time].attrs.items()))\n",
    "            for rx_gain in dataset[cmd][cmd_time].keys():\n",
    "               # print(\"   RX gain:\", rx_gain)\n",
    "                for rx in dataset[cmd][cmd_time][rx_gain].keys():\n",
    "                    print(\"\")\n",
    "                    #print(\"     RX:\", rx)\n",
    "                    #print(\"       Measurement items:\", list(dataset[cmd][cmd_time][rx_gain][rx].keys()))\n",
    "        elif cmd == 'saveiq_w_tx':\n",
    "            cmd_time = list(dataset[cmd].keys())[0]\n",
    "            #print(\"  Timestamp:\", get_time_string(cmd_time))\n",
    "            #print(\"  Command meta data:\", list(dataset[cmd][cmd_time].attrs.items()))\n",
    "            for tx in dataset[cmd][cmd_time].keys():\n",
    "                #print(\"   TX:\", tx)\n",
    "                \n",
    "                if tx == 'wo_tx':\n",
    "                    for rx_gain in dataset[cmd][cmd_time][tx].keys():\n",
    "                        #print(\"       RX gain:\", rx_gain)\n",
    "                       # print(dataset[cmd][cmd_time][tx][rx_gain].keys())\n",
    "                        for rx in dataset[cmd][cmd_time][tx][rx_gain].keys():\n",
    "                            #print(\"         RX:\", rx)\n",
    "                            #print(\"           Measurement items:\", list(dataset[cmd][cmd_time][tx][rx_gain][rx].keys()))\n",
    "                            repeat = np.shape(dataset[cmd][cmd_time][tx][rx_gain][rx]['rxsamples'])[0]\n",
    "                            #print(\"         repeat\", repeat)\n",
    "\n",
    "                            samplesNotx =  dataset[cmd][cmd_time][tx][rx_gain][rx]['rxsamples'][:repeat, :]\n",
    "                            namelist = rx.split('-')\n",
    "                            noise[namelist[1]] = samplesNotx\n",
    "                else:\n",
    "                    for tx_gain in dataset[cmd][cmd_time][tx].keys():\n",
    "                        #print(\"     TX gain:\", tx_gain)\n",
    "                        for rx_gain in dataset[cmd][cmd_time][tx][tx_gain].keys():\n",
    "                            #print(\"       RX gain:\", rx_gain)\n",
    "                            #print(dataset[cmd][cmd_time][tx][tx_gain][rx_gain].keys())\n",
    "                            for rx in dataset[cmd][cmd_time][tx][tx_gain][rx_gain].keys():\n",
    "                                repeat = np.shape(dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx]['rxsamples'])[0]\n",
    "                                #print(\"         RX:\", rx, \"; samples shape\", np.shape(dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx]['rxsamples']))\n",
    "                                #print(\"         Measurement items:\", list(dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx].keys()))\n",
    "                                # print(\"         rxloc\", (dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx]['rxloc'][0]))\n",
    "                                # peak avg check\n",
    "                                \n",
    "                                txrxloc.setdefault(tx, []).extend([rx]*repeat)\n",
    "                                rxsamples = dataset[cmd][cmd_time][tx][tx_gain][rx_gain][rx]['rxsamples'][:repeat, :]\n",
    "                                data.setdefault(tx, []).append(np.array(rxsamples))\n",
    "\n",
    "        else:                       \n",
    "            print('Unsupported command: ', cmd)\n",
    "\n",
    "    return data, noise, txrxloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9887,
   "id": "07ebe29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotOnePSDForEachLink(rx_data, txrxloc, samp_rate=2e6, repeats=10):\n",
    "    for txname in rx_data:\n",
    "        print(txname)\n",
    "        for i in range(0, len(rx_data[txname]), repeats):\n",
    "            plt.figure()\n",
    "            plt.psd(rx_data[txname][i][1], Fs = samp_rate/1000)\n",
    "            #plt.ylim(-110, -60)\n",
    "            #plt.yticks(ticks=[-110, -100, -90, -80, -70, -60])\n",
    "            plt.grid('on')\n",
    "            plt.title('TX: {} RX: {}'.format(txname, txrxloc[txname][i]))\n",
    "            plt.xlabel('Frequency (kHz)')\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fd61f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9888,
   "id": "b628d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURPOSE: perform preamble synchronization\n",
    "#          Uses the (complex-valued) preamble signal. The cross-correlation \n",
    "#          of the preamble signal and the received signal (at the time\n",
    "#          when the preamble is received) should have highest magnitude\n",
    "#          at the index delay where the preamble approximately starts.  \n",
    "# INPUT:   rx0: received signal (with a frequency offset)\n",
    "#          preambleSignal: complex, known, transmitted preamble signal \n",
    "# OUTPUT:  lagIndex: the index of rx0 where the preamble signal has highest \n",
    "#              cross-correlation\n",
    "#\n",
    "def crossCorrelationMax(rx0, preambleSignal):\n",
    "\n",
    "    # Cross correlate with the preamble to find it in the noisy signal\n",
    "    lags      = signal.correlation_lags(len(rx0), len(preambleSignal), mode='valid')\n",
    "    xcorr_out = signal.correlate(rx0, preambleSignal, mode='valid')\n",
    "    xcorr_mag = np.abs(xcorr_out)\n",
    "    # Don't let it sync to the end of the packet.\n",
    "    packetLenSamples = Frame_length\n",
    "    maxIndex = np.argmax(xcorr_mag[:len(xcorr_mag)-packetLenSamples])\n",
    "    lagIndex = lags[maxIndex]\n",
    "    \n",
    "#     print('The old lag ' + str(lagIndex))\n",
    "    # Try to use the second lagIndex if the first one is not strong enough\n",
    "    packetLenSamples = 0\n",
    "    maxIndex2 = np.argmax(xcorr_mag[:len(xcorr_mag)-packetLenSamples])\n",
    "    lagIndex2 = lags[maxIndex2]\n",
    "    \n",
    "# #     print(\"xcorr_mag[maxIndex2]\", xcorr_mag[maxIndex2])\n",
    "    \n",
    "    if abs(xcorr_mag[maxIndex2]) > abs(xcorr_mag[maxIndex]):\n",
    "        lagIndex = lags[maxIndex2] - Frame_length\n",
    "        print('The new lag ' + str(lagIndex))\n",
    "    else:\n",
    "        print('The old lag ' + str(lagIndex))\n",
    "    #Plot the selected signal.\n",
    "    plt.figure(1)\n",
    "    fig, subfigs = plt.subplots(2,1)\n",
    "    subfigs[0].plot(np.real(rx0), label='Real RX Signal')\n",
    "    subfigs[0].plot(np.imag(rx0), label='Imag RX Signal')\n",
    "    scale_factor = np.mean(np.abs(rx0))/np.mean(np.abs(preambleSignal))\n",
    "    subfigs[0].plot(range(lagIndex, lagIndex + len(preambleSignal)), scale_factor*np.real(preambleSignal), label='Preamble')\n",
    "    #subfigs[0].legend()\n",
    "    subfigs[1].plot(lags, xcorr_mag, label='|X-Correlation|')\n",
    "    plt.xlabel('Sample Index', fontsize=14)\n",
    "    plt.show()\n",
    "    #plt.tight_layout()\n",
    "\n",
    "    return lagIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9889,
   "id": "fdc19c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2bits(message):\n",
    "    # Convert to characters of '1' and '0' in a vector.\n",
    "    temp_message = []\n",
    "    final_message = []\n",
    "    for each in message:\n",
    "        temp_message.append(format(ord(each), '07b'))\n",
    "    for every in temp_message:\n",
    "        for digit in every:\n",
    "            final_message.append(int(digit))\n",
    "    return final_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9890,
   "id": "6f47bb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binvector2str(binvector):\n",
    "    #binvector = binvector[0]\n",
    "    length = len(binvector)\n",
    "    eps = np.finfo('float').eps\n",
    "    if abs(length/7 - round(length/7)) > eps:\n",
    "        print('Length of bit stream must be a multiple of 7 to convert to a string.')\n",
    "    # Each character requires 7 bits in standard ASCII\n",
    "    num_characters = round(length/7)\n",
    "    # Maximum value is first in the vector. Otherwise would use 0:1:length-1\n",
    "    start = 6\n",
    "    bin_values = []\n",
    "    while start >= 0:\n",
    "        bin_values.append(int(math.pow(2,start)))\n",
    "        start = start - 1\n",
    "    bin_values = np.array(bin_values)\n",
    "    bin_values = np.transpose(bin_values)\n",
    "    str_out = '' # Initialize character vector\n",
    "    for i in range(num_characters):\n",
    "        single_char = binvector[i*7:i*7+7]\n",
    "        value = 0\n",
    "        for counter in range(len(single_char)):\n",
    "            value = value + (int(single_char[counter]) * int(bin_values[counter]))\n",
    "        str_out += chr(int(value))\n",
    "    return str_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9891,
   "id": "14fe25e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURPOSE: Convert binary data to M-ary by making groups of log2(M)\n",
    "#          bits and converting each bit to one M-ary digit.\n",
    "# INPUT: Binary digit vector, with length as a multiple of log2(M)\n",
    "# OUTPUT: M-ary digit vector\n",
    "def binary2mary(data, M):\n",
    "\n",
    "    log2M   = round(np.log2(M))\n",
    "    # integer number of bits per group\n",
    "    if (len(data) % log2M) != 0:\n",
    "        print('Input to binary2mary must be divisible by log2(m).')\n",
    "    data.shape = (len(data)//log2M, log2M)\n",
    "    binaryValuesArray = 2**np.arange(log2M)\n",
    "    marydata = data.dot(binaryValuesArray)\n",
    "    return marydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9892,
   "id": "db1237df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURPOSE: convert input data stream to signal space values for\n",
    "#          a particular modulation type (as specified by the inputVec\n",
    "#          and outputVec).\n",
    "# INPUT: data (groups of bits)\n",
    "# OUTPUT: signal space values\n",
    "def lut(data, inputVec, outputVec):\n",
    "    if len(inputVec) != len(outputVec):\n",
    "        print('Input and Output vectors must have identical length')\n",
    "    # Initialize output\n",
    "    output = np.zeros(data.shape)\n",
    "    # For each possible data value\n",
    "    eps = np.finfo('float').eps\n",
    "    for i in range(len(inputVec)):\n",
    "        # Find the indices where data is equal to that input value\n",
    "        for k in range(len(data)):\n",
    "            if abs(data[k]-inputVec[i]) < eps:\n",
    "                # Set those indices in the output to be the appropriate output value.\n",
    "                output[k] = outputVec[i]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a1579",
   "metadata": {},
   "source": [
    "# Data Demodulation Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9894,
   "id": "a40cb119",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Protocol parameters!!!\n",
    "'''\n",
    "FFT = 64 # FFT size for extracting IQ sample in each subcarrier\n",
    "OFDM_size = 80 # OFDM symbol with cyclic prefix\n",
    "data_size = 48 # data_subcarriers\n",
    "mess_length = 560\n",
    "Frame_length = 3040\n",
    "# packet = 6000 # number of bits per pseudonym bit\n",
    "# samples = packet//10 # number of samples per chip\n",
    "CP = 16\n",
    "repeat =10\n",
    "actual_message='I have worked in SPAN Lab for the last three & half years.I implemented Pseudonymetry in POWDER.'\n",
    "len(actual_message)\n",
    "\n",
    "mess_bits = len(text2bits(actual_message))\n",
    "\n",
    "mess_per_repeat =4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9895,
   "id": "990f05eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CP = FFT//4  # 25% cyclic prefix\n",
    "pilotValue = 2.83+2.83j # known values for pilots\n",
    "pseudonymValue = 1.4142+1.4142j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9896,
   "id": "aa450a3d-54f4-4f00-b59f-de6536de92ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "allCarriers = np.array([-32,-31,-30,-29,-28,-27,-26,-25,-24,-23,-22,-21,-20,-19,-18,-17,-16,-15,-14,-13,-12,-11,-10,-9,-8,-7,-6,\n",
    "                    -5,-4,-3,-2,-1,0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31])\n",
    "dataCarriers = np.array([-26,-25,-24,-23,-22,-20,-19,-18,-17,-16,-15,-14,-13,-12,-11,-10,-9,-8,-6,\n",
    "                    -5,-4,-3,-2,-1,0,1,2,3,4,5,6,8,9,10,11,12,13,14,15,17,18,19,20,22,23,24,25,26])\n",
    "pseudonymCarrier = np.array([16])\n",
    "pilotCarriers = np.array([-21,-7,7,21])\n",
    "guardCarriers = np.array([-32,-31,-30,-29,-28,-27,27,28,29,30,31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9897,
   "id": "9bc1334b-8d1e-4a6a-a734-a1581141210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate HTSTF signals for time synchronization\n",
    "def Generate_HTSTF():\n",
    "    data = scipy.io.loadmat('HTSTF.mat')\n",
    "    new_data = data['stf'].reshape((1,len(data['stf'])))\n",
    "    preamble = np.tile(new_data,10)[0]\n",
    "    return preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9898,
   "id": "ee247de7-f115-43b4-bd71-ee22f2a5a6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FFT for data of window size=64\n",
    "def DFT_data(x, n =64):\n",
    "    return np.fft.fft(x,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9899,
   "id": "9fac4d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "calculates the distance between two arrays.\n",
    "'''\n",
    "def Distance(X,Y):\n",
    "    count = 0\n",
    "    for i in range(len(X)):\n",
    "        if X[i]!= Y[i]:\n",
    "            count +=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9900,
   "id": "2bdfbd69-6b4d-488f-9dec-b9ae3e09c268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURPOSE: Find the symbols which are closest in the complex plane \n",
    "#          to the measured complex received signal values.\n",
    "# INPUT:   Received r_hat values (output of matched filter downsampled),\n",
    "#          and possible signal space complex values. \n",
    "# OUTPUT:  m-ary symbol indices in 0...length(outputVec)-1\n",
    "def findClosestComplex(r_hat, outputVec):\n",
    "    # outputVec is a 4-length vector for QPSK, would be M for M-QAM or M-PSK.\n",
    "    # This checks, one symbol sample at a time,  which complex symbol value\n",
    "    # is closest in the complex plane.\n",
    "    data_out = [np.argmin(np.abs(r-outputVec)) for r in r_hat]\n",
    "    return data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9901,
   "id": "89acea47-f40e-4b32-a268-a2119ebbbdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose: Convert M-ary data to binary data\n",
    "#          each m-ary value input in \"data\" is converted to\n",
    "#          log2(M) binary values.\n",
    "# INPUT: M-ary digit vector\n",
    "# OUTPUT: Binary digit vector, with length equal to the number\n",
    "#         of values in data multiplied by log2(M)\n",
    "def mary2binary(data, M):\n",
    "    length = len(data) # number of values in data\n",
    "    log2M = round(np.log2(M)) # integer number of bits per data value\n",
    "    format_string = '0' + str(log2M) + 'b'\n",
    "    binarydata = np.zeros((1,length*log2M))\n",
    "    count = 0\n",
    "    for each in data:\n",
    "        binval = format(int(each), format_string)\n",
    "        for i in range(log2M):\n",
    "            binarydata[0][count+i] = int(binval[i])\n",
    "        count = count + log2M\n",
    "    return binarydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9902,
   "id": "b967e1a1-c768-475f-9158-9b86db39ee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURPOSE: Plot the signal symbol samples on a complex plane\n",
    "# INPUT:   Received complex values (output of matched filter downsampled)\n",
    "# OUTPUT:  none\n",
    "def constellation_plot(rx4):\n",
    "    # I like a square plot for the constellation so that both dimensions look equal\n",
    "    plt.figure(figsize=(5,5))\n",
    "    ax = plt.gca() \n",
    "    ax.set_aspect(1.0) # Make it a square 1x1 ratio plot\n",
    "    plt.plot(np.real(rx4), np.imag(rx4),'ro')\n",
    "    plt.ylabel('Imag(Symbol Sample)', fontsize=14)\n",
    "    plt.xlabel('Real(Symbol Sample)', fontsize=14)\n",
    "    plt.grid('on')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9903,
   "id": "837635d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_Folders(x):\n",
    "    r = []\n",
    "    for root, dirs, files in os.walk(x):\n",
    "        r.append(dirs)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9904,
   "id": "c2618343-f1db-4868-a382-5127a7a693d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def channelEstimate(x):\n",
    "    pilots = x[pilotCarriers]  # extract the pilot values from the RX signal\n",
    "    H_at_pilots = pilots / pilotValue # divide by the transmitted pilot values\n",
    "    \n",
    "    # Perform interpolation between the pilot carriers to get an estimate of the channel in the data carriers. \n",
    "    H_abs=scipy.interpolate.interp1d(pilotCarriers, abs(H_at_pilots), kind='nearest', fill_value='extrapolate')(allCarriers)\n",
    "    H_phase = scipy.interpolate.interp1d(pilotCarriers, np.angle(H_at_pilots), kind='nearest', fill_value='extrapolate')(allCarriers)\n",
    "    H_estimate = H_abs * np.exp(1j*H_phase)\n",
    "    \n",
    "    return H_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9905,
   "id": "72fe1acd-c24f-4905-970e-e80e0e91bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize(OFDM_demod, Hest):\n",
    "    return OFDM_demod / Hest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9906,
   "id": "d787b024-f077-48b0-8ccf-5a615eea7d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''PURPOSE: To recover the data signal'''\n",
    "def OFDM_RX(data):\n",
    "    for i in range(len(data)//(OFDM_size)):\n",
    "        data_cp = data[i*(OFDM_size):(i+1)*(OFDM_size)]\n",
    "        data_without_cp = data_cp[CP:]\n",
    "        \n",
    "        # Generate frequency domain signal\n",
    "        OFDM_freq = np.fft.fft(data_without_cp,n=FFT)\n",
    "        \n",
    "        H_est = channelEstimate(OFDM_freq) # estimate the channel\n",
    "        \n",
    "        OFDM_est = equalize(OFDM_freq,H_est) # equalization with estimated channel\n",
    "        \n",
    "        OFDM_data = OFDM_est[dataCarriers] # extract the data signal\n",
    "        if i == 0:\n",
    "            OFDM_swap =  OFDM_data\n",
    "        else:\n",
    "            OFDM_signal = np.concatenate((OFDM_swap,  OFDM_data))\n",
    "            OFDM_swap = OFDM_signal\n",
    "    return OFDM_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9907,
   "id": "a4d770b8-e5cb-4a72-a78f-0de02747988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_Data_BER(x):\n",
    "    outputVec = np.array([1+1j, -1+1j, 1-1j, -1-1j])\n",
    "    qpsk_samples = OFDM_RX(x)\n",
    "    data_ber  = 0.0\n",
    "    for i in range(len(x)//mess_length):\n",
    "        mess_data = x[i*mess_length:(i+1)*mess_length]\n",
    "        est_data = OFDM_RX(mess_data)\n",
    "        # constellation_plot(est_data)\n",
    "        mary_out  = findClosestComplex(est_data, outputVec)\n",
    "        data_bits = mary2binary(mary_out, 4)[0]\n",
    "        # print('Length of Data bits:',len(data_bits))\n",
    "        print('Detected Message:',binvector2str(data_bits))\n",
    "        data_ber += Distance(data_bits, text2bits(actual_message))\n",
    "\n",
    "    return data_ber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9908,
   "id": "a24c8013",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Checks if pseudonyms are decoded correctly in each repeat of shout transmission.\n",
    "One experiment has 10 repeats.\n",
    "'''\n",
    "def Average_Data_Error(x):\n",
    "    # Load parameters from the JSON file which describe what was measured\n",
    " \n",
    "    #folder = x\n",
    "    jsonfile = \"save_iq_w_tx_file.json\"\n",
    "    rxrepeat, samp_rate, txlocs, rxlocs = JsonLoad(x, jsonfile)\n",
    "    # Load data from the HDF5 file, save IQ sample arrays\n",
    "    rx_data, rx_noise, txrxloc = traverse_dataset(x)\n",
    "    samp_rate = 2e6\n",
    "\n",
    "    txloc = 'cbrssdr1-ustar-comp'\n",
    "    rxloc = 'cbrssdr1-browning-comp'\n",
    "    # rxloc = 'cbrssdr1-meb-comp'\n",
    "    \n",
    "    #Calculate SNR\n",
    "    Noise = rx_noise['browning'][0]\n",
    "    # Noise = rx_noise['meb'][0]\n",
    "    noise_power = sum(abs(Noise)**2)/len(Noise)\n",
    "\n",
    "    rx_data[txloc] = np.vstack(rx_data[txloc])\n",
    "    rxloc_arr = np.array(txrxloc[txloc])       \n",
    "\n",
    "    # initialize error\n",
    "    data_BER = 0\n",
    "    P_s = 0\n",
    "    for i in range(repeat):\n",
    "        repNum = i\n",
    "        rx_data[txloc] = np.vstack(rx_data[txloc])\n",
    "        rxloc_arr = np.array(txrxloc[txloc])\n",
    "        rx0 = rx_data[txloc][rxloc_arr==rxloc][repNum]\n",
    "    \n",
    "\n",
    "        # synchronize pseudonym using preamble signal\n",
    "        preambleSignal = Generate_HTSTF()\n",
    "        lagIndex = crossCorrelationMax(rx0,preambleSignal)\n",
    "        \n",
    "        start = lagIndex + len(preambleSignal)\n",
    "        Rx_signal = rx0[start:start+mess_length]\n",
    " \n",
    "        data_BER +=  Calculate_Data_BER(Rx_signal)\n",
    " \n",
    "        P_s += sum(abs(Rx_signal)**2)/len(Rx_signal)\n",
    "    \n",
    "    signal_power = P_s/repeat\n",
    "    \n",
    "    return data_BER, signal_power, noise_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9909,
   "id": "40f28914",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Computes the average pseudonym error in the experiment.\n",
    "Experiment data is stored in folders that contain 10 repeats each.\n",
    "'''\n",
    "def Prob_Data_Error(x):\n",
    "    folders = Extract_Folders(x)[0]\n",
    "    num_folders = len(folders)\n",
    "    print('Number of folders:',num_folders)\n",
    "    Data_bit_BER = 0\n",
    "    signal,noise = 0,0\n",
    "    for i in range(num_folders):\n",
    "        print(folders[i])\n",
    "        error,s,n= Average_Data_Error(x + '/'+folders[i])\n",
    "        \n",
    "        Data_bit_BER += error\n",
    "        signal += s\n",
    "        noise += n\n",
    "\n",
    "    Eb_No = 10*(np.log10(0.5*(signal-noise)/noise))\n",
    "\n",
    "    Data_BER = Data_bit_BER/(num_folders*repeat*mess_per_repeat*mess_bits)\n",
    "    \n",
    "    # print(\"total number of pseudonym bit errors:\", Data_bit_BER)\n",
    "    # print('Data BER:',Data_BER)\n",
    "    # print('Eb/No:',Eb_No)\n",
    "    return Data_BER, Eb_No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9910,
   "id": "730424fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of folders: 4\n",
      "Shout_meas_08-17-2024_10-56-35\n",
      "The new lag 1785\n",
      "gb!fe0 6xg |asm |hR7e & hAlfDxeaz9nI imCII\u000b",
      "enDu$0Pse@JmcMe|ri`in POWDER.\n",
      "The new lag -55\n",
      "Detected Message: I`l)z$ gm4_Ghdio S\\`F XAj\u0000fex0vhe lew4)uis'a\u0001& jalf$ygiza?E\"%mple/e*vpt PseMJ]cMetZ}h,n\u0000QOWDOVn\n",
      "The old lag 1145\n",
      "Detected Message: I(hare\u0000worked\"(\u0010\u0003tan Yaf@fg10the last(thR5a & hkILESear3?I hmpmEma,dad TSe_aN_cMMvSy`lf QO~L]Fn\n",
      "The new lag -695\n",
      "Detected Message: I `qv`!workEd!)n$ST\u0001N Lab be3 |he lasdatHRwd\u0001\"0half {oasq.M aeSLA-m\u000eve'\"TseulnoyM\u000ftry in POWDER.\n",
      "The new lag 1225\n",
      "Detected Message: I la>e ovkMd`)o\u0000STAN Lab fg: ~jw`|ast!thRga$' hAlfD{girs>I imsiI/Fu%(PseDJ]cY\u000fV3y in TM6\f",
      "_V.\n",
      "The new lag -615\n",
      "Detected Message: i l >e go$KMd !o0\u001b|af MCJ\u0000gmp tl%`lgs|`thsge\u0001& |alf$y'ars/I ioSMI+E\n",
      "d%5*PseueOki%try -n PO~DGR.\n",
      "The new lag 585\n",
      "Detected Message: i`(yvq workedb!~0[p\u0001N\u0000Lab gg1!the laS|!thsee\u0001\"0xalf yeizy.I ioAmI\u000fMntuf$P3eudOoki\u0005~2i8-n\u0000POWLER.\n",
      "The new lag -535\n",
      "Detected Message: i lave workMd`ho QtQN`Mcf fg2 vl% lest`thRge & ha,f\u0000{eaz{.I imrle-ejpqd PseudOoymevRy i~ P_WDER.\n",
      "The new lag 665\n",
      "Detected Message: i\"da~e gm2_'dbio0Cxan Lab Fe0 thg last!diRea\u0005\"$himFA[e`rs.I iopLm\u000fajtef PseHN}cY\u000ftS9 in POWDOVj\n",
      "The new lag -455\n",
      "Detected Message: I\"dare worked\"in\u0000YTAN Lgf fgp the last thRee & half Ye`[s/E imqii-Mnted TsdmN]cMev:y in u_WDWR(\n",
      "Shout_meas_08-17-2024_10-59-02\n",
      "The old lag 1506\n",
      "Detected Message: M `(~!$worked\")\u0000ST@N \\Cf fe2(vhe last thRfa & half\u0000ymIr{.I imAmI-Ejved Ps$ueNo{MetSy in POWDER.\n",
      "The old lag 386\n",
      "Detected Message: i l!ve wmf[Md mn SPAN!Lgf`fe9:the last tirgq\u0005# hamF`Smazq/Ib!ermI/M*daf2Psdudo~kmot3y(io\u0000POVD]V.\n",
      "The new lag -734\n",
      "Detected Message: Ij(ave worked in \u0013PAN Lab\u0000fe9 the |gs<cthret & jalf yeazsnI imriI\u000b",
      "ejvd6(PsduDonyI%tSyp-f\u0000P_\u0017M_B.\n",
      "The new lag 466\n",
      "Detected Message: Eb`ave worked\"!o SPAL\u0004\u0019GF@fe1 the last!lYR'a & hamn\u0001QeaRq>I imslI/e*vq$ PseumNcI\u0007Try\"in POWDEB*\n",
      "The old lag 1666\n",
      "d`in4[pAN \u0019Cb\u0000fe2 4he yGG-ktHsu`!'$jalf Yeazy.A )oCII\u000b",
      "M\n",
      "Fe% Pseudo~ymetRi (n \u0010_WDER.\n",
      "The new lag -174\n",
      "Detected Message: I have$gmt-d i~\u0014\u000b",
      "T\u0001n YeN\u0000for t(e las| thrge & halF\u0004seaZ{oA ioqMI\u000fM.fd'\"Pseu`Nncm%Try )n POWMMV.\n",
      "The new lag 1026\n",
      "Detected Message: I have worke``in\u0004\u000b",
      "t!g Lab ggr\"v(e`lcstatjz5q & half!{eir;&I )msmA/Andd$*Tse`N]cM\u0007\\ri in POWDOR.\n",
      "The new lag 2226\n",
      "Detected Message: I\"`!v% o]d[/hD,o SPAN \tgF@fe90<xu`last!uHSee!& half\u0004ym`zs.I ioCII\u000fM.ted TseudnOkmg~Sy in POWDGB.\n",
      "The new lag 386\n",
      "Detected Message: I lqre wOf{%d in SpAN Lcb\u0000for 4le ,asl thrfe\u0004&$8aln\u0001yeazy.I imRmA/M*fee0Pseudno{M%tr}(-n POW@GV.\n",
      "The new lag 1586\n",
      "Detected Message: I``ava worom` io SPAN Lcb fgr 6he mgW}athRee\u0001&$half {e`rs/E !mpmA/m\n",
      "dt$ P3du`ooiMetRy`mn POWDMR.\n",
      "Shout_meas_08-17-2024_11-08-45\n",
      "The new lag 1109\n",
      "Detected Message: i hav% o`G``m~$\u0013PAF Lab fg\" 4he |es| three & jalf {earq.I imqleme*ted PseudonymetRy io\u0000TMwHER.\n",
      "The new lag -11\n",
      "Detected Message: I have pO-d )n SPAN Mab fg2 <he lastathr'e & half ye`Z1.A impmA-E\u000eted Pseudolkmetry in POWDER.\n",
      "The new lag 1909\n",
      "Detected Message: m(dive wo2kEd in$SpAN Mab Fe02the lesd`three & hald\u0004Qehzq.I imcMI/AjDdg Pseudooc}-tRy in POWD]R.\n",
      "The new lag 789\n",
      "Detected Message: I(havu workmddan0\u0013taN!\u0019CJ\u0000fe2 the`lesththRwe\u0000& half yeasy.I impha-e.vet Tseudonk]ot2y hn\u0000POVLOR.\n",
      "The new lag -331\n",
      "Detected Message: M  `>$ vorkMd\"io \u0013pAN ]cn fm2 the last`|Hrea & half yea{s.I implI-Entef PseDNocM\u000fTR}`)n P_WDOR.\n",
      "The old lag 1589\n",
      "Detected Message: I `iv%$worKed in SpaN Lab fo20the last thRee & half yeArs>I imCiA-M*ded Pseudonym%vry`$o\u0000POWDER.\n",
      "The new lag -251\n",
      "Detected Message: I\"`a~d workEd\u0000)n Sp\u0001N Lcb fg2 thg |cSd`thred$& half years.A imalA-ented PsewdNo{Me|ryp,w\u0000P_WDUF.\n",
      "The new lag 949\n",
      "Detected Message: I dav%\u0000workOd in\u0000SPAN Lab fgr t(e lgw4ctiree & hamF$[eazs.I impmI-m\n",
      "tdd Pseuln|kMotry0)n Q\u001fwLWR\u000e\n",
      "The new lag 2149\n",
      "d ) ST\u0001n \u0019cf fg00vx% last`uhree!6 himf yeazy.A0hmqmA/ejded PSe}hN_cIMtRy in U\u001f~H_R.\n",
      "The old lag 1029\n",
      "ab fm0 the las|!thRed!&\u0014xalf\u0000qgArs.A hmbII-Ended Pseudnn{I\u000fv\u0012y in POWDE\u0012.\n",
      "Shout_meas_08-17-2024_11-14-51\n",
      "The new lag 2158\n",
      "Detected Message: I xAve`worke$ y. SPAO Lac fr the last th`ee & half yuars.\t implemented!\u0010weudenymetry in POWDER.\n",
      "The old lag 1038\n",
      "Detected Message: I have worke$(in S@EN Lar\"r/r!The last threm \u0006 half yeers\n",
      "\n",
      " kmple|en4ed@\u0010veudonymedry iN POWDEZ&\n",
      "The new lag -82\n",
      "Detected Message: I\u0000jave 1k{)e$!kN sPEJ La3 for!``e!lart tlvee`\u0006 half(ytars\u000e\n",
      "\u0000implem'o4Ed\u0000\u0010wmudonymedr{ ij POWDER.\n",
      "The old lag 1118\n",
      "Detected Message: H have 7krked ij SPAN Lab fob$phe\u0000la{t0t(vee & half yea`s\u000e\u0018 implemented PseudonymdtrY in XGWDER.\n",
      "The new lag -2\n",
      "Detected Message: I$have uorke$ in SPAN Lar\"bor The!last t`ree\"\u000e hafg\"ye!rs\n",
      "\n",
      " kMplemenvEd`PseudonYmetry\u0000kn PNWDAR.\n",
      "The old lag 1918\n",
      "plem6n4ed\u0000\u0012weudonymedry in POWDER/!RPAN Lab\"f?r the last thrme & half(years*\u001a\u0004k\n",
      "The new lag 78\n",
      "Detected Message: I#\u0001Ge w_bke$*ijb\u0013REN Lab\"b/21the lqrt40lza-h, hIml\u0005yea2s\u000e\u0013 iiplamentdd\u0000\u0002vmed/n=medr{\u0001iJ*POWDES/\n",
      "The new lag 1278\n",
      "Detected Message: I haVe 7o{jed io \u0013PAN Laq0f/2 the!lcsd`th2e'\"\u0006 hadf Years\u000eI!kiplemen4mT\u0000Psmufonymetry(yl#POSD\u0005R.\n",
      "The new lag 158\n",
      "Detected Message: I have worje$!kn SPAN Lab\"vr the last three & half iears*\u001a implem5ntel Pseudonymetry in POWDER/\n",
      "The old lag 1358\n",
      "Detected Message: I hCwe worked IncS@AN Lic22r the l`st4thrEE!& half yeabb iMplele.tedE\u0000smudonymetry in POWDER.\n"
     ]
    }
   ],
   "source": [
    "#x,y,AWGN = Prob_Pseudonym_Error(\"10dB_gain\")\n",
    "x,y = Prob_Data_Error(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9911,
   "id": "b97bc262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR: 6.37381627973749 \n",
      " Pseudonym_BER: 0.022163318452380953\n"
     ]
    }
   ],
   "source": [
    "print('SNR:',y,'\\n Pseudonym_BER:',x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
